"""
Mint.ai Visibility MCP Server - Version 3.5.2 (LLM Guidance Advanced)

Ce serveur MCP retourne des DATASETS TABULAIRES lisibles.
Les commentaires d√©taill√©s ci-dessous guident le LLM sur TOUS les param√®tres,
en particulier les param√®tres OPTIONNELS (dates, models).

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
GUIDE COMPLET POUR LE LLM:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

1Ô∏è‚É£ CHERCHER UN DOMAINE/TOPIC?
   ‚Üí Utilise d'abord: get_domains_and_topics()
   ‚Üí Cela retourne la liste des IDs disponibles + mapping
   ‚Üí Exemple: "IBIS France" ‚Üí domainId: "694a6c9c..." + topicId: "694a6d61..."

2Ô∏è‚É£ ANALYSER LA VISIBILIT√â?
   ‚Üí Utilise: get_visibility_scores(domainId, topicId, output_format="tabular")
   ‚Üí Cela retourne une BELLE TABLE avec:
      - Lignes: Date + Model
      - Colonnes: Brand + Competitors
      - Stats: Moyenne, Min, Max par entit√©

3Ô∏è‚É£ PARAM√àTRES DE DATES (OPTIONNELS) ‚ö†Ô∏è TR√àS IMPORTANT!
   
   SC√âNARIO 1: L'utilisateur NE MENTIONNE PAS DE DATES
   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   Exemple user: "Analyse IBIS France" (pas de dates mentionn√©es)
   ‚Üí NE PASSE PAS startDate ni endDate
   ‚Üí Le serveur retourne TOUTES LES DONN√âES DISPONIBLES ‚úÖ
   ‚Üí Comportement: Cherche la plus ancienne jusqu'√† aujourd'hui
   ‚Üí Avantage: Vue compl√®te historique
   
   SC√âNARIO 2: L'utilisateur MENTIONNE UNE PLAGE
   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   Exemple user: "Donn√©es de d√©cembre 2025"
   ‚Üí Calcule automatiquement:
      startDate="2025-12-01", endDate="2025-12-31"
   ‚Üí Format: "YYYY-MM-DD" (ex: "2025-12-15")
   
   SC√âNARIO 3: L'utilisateur DEMANDE LES 30 DERNIERS JOURS
   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   Exemple user: "Montre les 30 derniers jours"
   ‚Üí Calcule automatiquement:
      endDate = aujourd'hui (ex: "2026-02-10")
      startDate = aujourd'hui - 30 jours (ex: "2026-01-11")
   
   SC√âNARIO 4: L'utilisateur DEMANDE TOUT
   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   Exemple user: "Montre-moi tous les donn√©es", "Tout depuis le d√©but"
   ‚Üí NE PASSE PAS startDate ni endDate
   ‚Üí Retour: Toutes les donn√©es disponibles ‚úÖ
   
   ‚ö° R√àGLE D'OR: Si pas de dates mentionn√©es ‚Üí OMETS les param√®tres!

4Ô∏è‚É£ PARAM√àTRE MODELS (OPTIONNEL) ‚ö†Ô∏è TR√àS IMPORTANT!
   
   MOD√àLES DISPONIBLES (7 au total, tous compatibles):
   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   
   Pour analyser les SCORES:
   ‚îú‚îÄ "GLOBAL"                    ‚Üê Score COMBIN√â (recommand√©, d√©faut)
   ‚îÇ  Utilise: Tous les mod√®les
   ‚îÇ  Cas d'usage: Analyse g√©n√©rale, comparaison fiable
   ‚îÇ
   ‚îú‚îÄ "gpt-5.1"                   ‚Üê Model OpenAI GPT-5.1 (nouvelle)
   ‚îÇ  Cas d'usage: R√©sultats OpenAI, comparaison avec GPT-5
   ‚îÇ
   ‚îú‚îÄ "sonar-pro"                 ‚Üê Model Perplexity Sonar Pro
   ‚îÇ  Cas d'usage: R√©sultats Perplexity, recherche avanc√©e
   ‚îÇ
   ‚îú‚îÄ "google-ai-overview"        ‚Üê Google AI Overview
   ‚îÇ  Cas d'usage: R√©sultats Google, AI Overview int√©gr√©
   ‚îÇ
   ‚îú‚îÄ "gpt-interface"             ‚Üê GPT Interface (ancienne)
   ‚îÇ  Cas d'usage: R√©sultats legacy, comparaison historique
   ‚îÇ
   ‚îú‚îÄ "gemini-3-pro-preview"      ‚Üê Google Gemini 3 Pro Preview
   ‚îÇ  Cas d'usage: R√©sultats Gemini, preview functionality
   ‚îÇ
   ‚îî‚îÄ "gpt-5"                     ‚Üê Model OpenAI GPT-5 (flagship)
      Cas d'usage: R√©sultats OpenAI premium, benchmark
   
   SC√âNARIO 1: L'utilisateur NE MENTIONNE PAS DE MOD√àLE
   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   Exemple user: "Analyse IBIS France" (pas de mod√®le mentionn√©)
   ‚Üí NE PASSE PAS le param√®tre 'models'
   ‚Üí Le serveur retourne TOUS LES MOD√àLES ‚úÖ
   ‚Üí R√©sultat: Table avec lignes pour chaque (date, model) combo
   ‚Üí Avantage: Voir l'√©volution sur TOUS les mod√®les
   
   SC√âNARIO 2: L'utilisateur DEMANDE UN SEUL MOD√àLE
   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   Exemple user: "Montre-moi les scores GPT-5.1"
   ‚Üí Passe: models="gpt-5.1"
   ‚Üí R√©sultat: Table filtr√©e sur GPT-5.1 uniquement
   
   SC√âNARIO 3: L'utilisateur DEMANDE PLUSIEURS MOD√àLES
   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   Exemple user: "Compare GPT-5.1, Sonar Pro et Gemini"
   ‚Üí Passe: models="gpt-5.1,sonar-pro,gemini-3-pro-preview"
   ‚Üí Format: S√©par√©s par virgules, SANS espaces
   ‚Üí R√©sultat: Table avec ces 3 mod√®les + GLOBAL
   
   SC√âNARIO 4: L'utilisateur DEMANDE LE GLOBAL
   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   Exemple user: "Juste le score global combin√©"
   ‚Üí Passe: models="GLOBAL"
   ‚Üí R√©sultat: Table avec GLOBAL uniquement (le plus rapide)
   
   ‚ö° R√àGLE D'OR: 
      - Pas de mention ‚Üí OMETS le param√®tre ‚Üí TOUS les mod√®les
      - Mentionne un mod√®le ‚Üí Passe ce mod√®le
      - Mentionne plusieurs ‚Üí Passe tous (s√©par√©s par virgule)

5Ô∏è‚É£ COMBINAISON: DATES + MODELS
   
   EXEMPLE COMPLET:
   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   User: "Montre-moi le GLOBAL pour les 7 derniers jours"
   
   ‚Üí Calcule dates:
      endDate = aujourd'hui (ex: "2026-02-10")
      startDate = 7 jours avant (ex: "2026-02-03")
   
   ‚Üí Filtre mod√®le:
      models = "GLOBAL"
   
   ‚Üí Appel:
      get_visibility_scores(
        domainId="...",
        topicId="...",
        startDate="2026-02-03",
        endDate="2026-02-10",
        models="GLOBAL",
        output_format="tabular"
      )

6Ô∏è‚É£ FORMAT DE SORTIE?
   
   Quatre options disponibles:
   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   
   "tabular" (D√âFAUT)
   ‚Üí Table Markdown lisible + stats auto-calcul√©es
   ‚Üí Meilleur pour: Analyse humaine, rapports
   ‚Üí Temps: Normal
   
   "csv"
   ‚Üí Format CSV pur (copier-coller dans Excel)
   ‚Üí Meilleur pour: Export Excel/Sheets
   ‚Üí Temps: Normal
   
   "json"
   ‚Üí JSON structur√© (headers, rows, stats, metadata)
   ‚Üí Meilleur pour: Int√©gration code, traitement automatis√©
   ‚Üí Temps: Normal
   
   "stats"
   ‚Üí Synth√®se stats uniquement (Moy/Min/Max par entit√©)
   ‚Üí Meilleur pour: Vue rapide, comparaisons
   ‚Üí Temps: ‚ö° 5x plus rapide que tabular

7Ô∏è‚É£ INTERPR√âTER LES R√âSULTATS?
   ‚Üí Cherche d'abord le R√âSUM√â PAR ENTIT√â (stats)
   ‚Üí Puis analyse le DATASET TABULAIRE (tendances)
   ‚Üí Colonnes = Brand + Competitors (comparer visibilit√©)
   ‚Üí Lignes = Dates + Models (voir √©volutions)

8Ô∏è‚É£ CAS D'USAGE RAPIDES:
   
   "Analyse compl√®te une r√©gion"
   ‚Üí Omets dates, mod√®les, format="tabular" (d√©faut)
   ‚Üí get_visibility_scores(domainId, topicId)
   
   "Vue rapide (synth√®se)"
   ‚Üí Omets dates, mod√®les, format="stats"
   ‚Üí get_visibility_scores(domainId, topicId, output_format="stats")
   
   "Compare GPT-5.1 vs Gemini"
   ‚Üí models="gpt-5.1,gemini-3-pro-preview"
   ‚Üí get_visibility_scores(domainId, topicId, models="gpt-5.1,gemini-3-pro-preview")
   
   "7 derniers jours, GLOBAL seulement"
   ‚Üí models="GLOBAL", calcule dates (-7j)
   ‚Üí get_visibility_scores(domainId, topicId, startDate="...", endDate="...", models="GLOBAL")
   
   "Export Excel aujourd'hui"
   ‚Üí output_format="csv"
   ‚Üí get_visibility_scores(domainId, topicId, output_format="csv")

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
R√âSUM√â DES PARAM√àTRES:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

PARAM√àTRE      | TYPE        | OPTIONNEL | D√âFAUT           | NOTES
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
domainId       | string      | ‚ùå REQUIS | N/A              | De get_domains()
topicId        | string      | ‚ùå REQUIS | N/A              | De get_domains()
startDate      | YYYY-MM-DD  | ‚úÖ OPT   | Anciennement     | Si omis: tout
endDate        | YYYY-MM-DD  | ‚úÖ OPT   | Aujourd'hui      | Si omis: tout
models         | string      | ‚úÖ OPT   | TOUS les mod√®les | S√©par√©s par ,
output_format  | string      | ‚úÖ OPT   | "tabular"        | tabular/csv/json/stats

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
"""

import asyncio
import json
import logging
import os
import sys
from datetime import date, timedelta
from typing import Any
from collections import defaultdict

import httpx
from mcp.server import Server
from mcp.types import Tool, TextContent
from mcp.server.sse import SseServerTransport

# Imports Starlette & Web
from starlette.applications import Starlette
from starlette.routing import Route
from starlette.middleware import Middleware
from starlette.middleware.cors import CORSMiddleware
from starlette.requests import Request
from starlette.responses import StreamingResponse, JSONResponse

# Configuration
MINT_API_KEY = os.getenv("MINT_API_KEY", "")
MINT_BASE_URL = os.getenv("MINT_BASE_URL", "https://api.getmint.ai/api")

# Logging vers stderr
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    stream=sys.stderr
)
logger = logging.getLogger(__name__)

if not MINT_API_KEY:
    logger.warning("‚ö†Ô∏è MINT_API_KEY environment variable is missing!")

# Cr√©ation du serveur MCP
server = Server("mint-visibility-mcp")


# ========== UTILITAIRES POUR DATASET TABULAIRE ==========

def create_tabular_dataset(raw_dataset: list[dict]) -> dict:
    """Transforme dataset brut en PIVOT TABLE structur√©"""
    if not raw_dataset:
        return {"error": "Aucune donn√©e"}
    
    pivot_data = {}
    all_entities = set()
    
    for row in raw_dataset:
        date_val = row.get("Date", "")
        model_val = row.get("Model", "")
        entity = row.get("EntityName", "")
        score = row.get("Score", 0)
        
        all_entities.add(entity)
        key = f"{date_val}|{model_val}"
        
        if key not in pivot_data:
            pivot_data[key] = {"Date": date_val, "Model": model_val}
        
        pivot_data[key][entity] = round(score, 2) if isinstance(score, (int, float)) else 0
    
    all_entities = list(all_entities)
    if "Brand" in all_entities:
        all_entities.remove("Brand")
        all_entities = ["Brand"] + sorted(all_entities)
    
    headers = ["Date", "Model"] + all_entities
    rows = []
    
    for key in sorted(pivot_data.keys()):
        row = {"Date": pivot_data[key]["Date"], "Model": pivot_data[key]["Model"]}
        for entity in all_entities:
            row[entity] = pivot_data[key].get(entity, None)
        rows.append(row)
    
    stats = {}
    for entity in all_entities:
        scores = [r[entity] for r in rows if r[entity] is not None]
        if scores:
            stats[entity] = {
                "average": round(sum(scores) / len(scores), 2),
                "min": round(min(scores), 2),
                "max": round(max(scores), 2),
                "count": len(scores)
            }
    
    return {
        "headers": headers,
        "rows": rows,
        "entities": all_entities,
        "stats": stats,
        "total_rows": len(rows),
        "total_entities": len(all_entities)
    }


def format_as_markdown_table(tabular_data: dict) -> str:
    """Formate en TABLE MARKDOWN"""
    if "error" in tabular_data:
        return f"‚ùå {tabular_data['error']}"
    
    headers = tabular_data.get("headers", [])
    rows = tabular_data.get("rows", [])
    
    if not rows:
        return "‚ùå Aucune donn√©e"
    
    md = "| " + " | ".join(headers) + " |\n"
    md += "|" + "|".join([":---" for _ in headers]) + "|\n"
    
    for row in rows:
        values = []
        for h in headers:
            val = row.get(h)
            if val is None:
                values.append("-")
            elif isinstance(val, float):
                values.append(f"{val:.2f}%")
            else:
                values.append(str(val))
        md += "| " + " | ".join(values) + " |\n"
    
    return md


def format_stats_summary(tabular_data: dict) -> str:
    """R√©sum√© des stats"""
    if "error" in tabular_data:
        return f"‚ùå {tabular_data['error']}"
    
    stats = tabular_data.get("stats", {})
    if not stats:
        return "‚ùå Aucune statistique"
    
    summary = "## üìä STATISTIQUES PAR ENTIT√â\n\n"
    summary += "| Entit√© | Moyenne | Min | Max | Mesures |\n"
    summary += "|--------|---------|-----|-----|----------|\n"
    
    for entity in sorted(stats.keys()):
        s = stats[entity]
        summary += f"| {entity} | {s['average']:.2f}% | {s['min']:.2f}% | {s['max']:.2f}% | {s['count']} |\n"
    
    return summary


# ========== API CALLS ==========

async def fetch_api(path: str, params: dict = None) -> dict:
    """Appel API Mint.ai"""
    if not MINT_API_KEY:
        raise RuntimeError("MINT_API_KEY environment variable is required")
    async with httpx.AsyncClient(timeout=30.0) as client:
        response = await client.get(
            f"{MINT_BASE_URL}{path}",
            params=params or {},
            headers={"X-API-Key": MINT_API_KEY}
        )
        response.raise_for_status()
        return response.json()


async def get_domains_and_topics() -> dict:
    """OUTIL #1: Liste domaines et topics"""
    domains = await fetch_api("/domains")
    all_topics = []
    mapping = {}
    
    for domain in domains:
        d_id = domain.get("id")
        d_name = domain.get("displayName", domain.get("name", "Unknown"))
        try:
            topics = await fetch_api(f"/domains/{d_id}/topics")
            for topic in topics:
                t_id = topic.get("id")
                t_name = topic.get("displayName", topic.get("name", "Unknown"))
                all_topics.append({
                    "id": t_id,
                    "name": t_name,
                    "domainId": d_id,
                    "domainName": d_name
                })
                mapping[f"{d_name} > {t_name}"] = {
                    "domainId": d_id,
                    "topicId": t_id
                }
        except Exception:
            continue
    
    return {
        "status": "success",
        "data": {
            "domains": domains,
            "topics": all_topics,
            "mapping": mapping
        }
    }


async def get_visibility_scores(
    domainId: str,
    topicId: str,
    startDate: str = None,
    endDate: str = None,
    models: str = None,
    output_format: str = "tabular"
) -> dict:
    """
    OUTIL #2: Scores de visibilit√© en dataset TABULAIRE

    ‚ö†Ô∏è PARAM√àTRES OPTIONNELS:
    - startDate/endDate: SI OMIS ‚Üí toutes les donn√©es
    - models: SI OMIS ‚Üí tous les mod√®les
    - output_format: "tabular" (d√©faut) | "csv" | "json" | "stats"
    """
    
    if not startDate or not endDate:
        endDate = date.today().strftime("%Y-%m-%d")
        startDate = (date.today() - timedelta(days=30)).strftime("%Y-%m-%d")
    
    base_params = {
        "startDate": startDate,
        "endDate": endDate,
        "latestOnly": "false",
        "page": "1",
        "limit": "100"
    }
    
    # R√©cup√©ration Global
    global_data = await fetch_api(
        f"/domains/{domainId}/topics/{topicId}/visibility/aggregated",
        base_params
    )
    available_models = global_data.get("availableModels", [])
    
    # Filtre models si sp√©cifi√©
    models_to_fetch = []
    if models:
        models_to_fetch = [m.strip() for m in models.split(",")]
    else:
        models_to_fetch = available_models
    
    # R√©cup√©ration par mod√®le
    by_model_data = {}
    for m in models_to_fetch:
        try:
            params = {**base_params, "models": m}
            by_model_data[m] = await fetch_api(
                f"/domains/{domainId}/topics/{topicId}/visibility/aggregated",
                params
            )
        except Exception:
            pass

    # Construction dataset
    dataset = []
    
    def add_rows(data, model_name):
        for entry in data.get("chartData", []):
            d = entry.get("date")
            dataset.append({
                "Date": d,
                "EntityName": "Brand",
                "EntityType": "Brand",
                "Score": entry.get("brand"),
                "Model": model_name
            })
            for c_name, c_score in entry.get("competitors", {}).items():
                dataset.append({
                    "Date": d,
                    "EntityName": c_name,
                    "EntityType": "Competitor",
                    "Score": c_score,
                    "Model": model_name
                })

    add_rows(global_data, "GLOBAL")
    for m in models_to_fetch:
        if m in by_model_data:
            add_rows(by_model_data[m], m)

    # Transformer en dataset tabulaire
    tabular = create_tabular_dataset(dataset)
    
    # Retourner selon le format
    if output_format == "csv":
        csv_text = ",".join(tabular.get("headers", [])) + "\n"
        for row in tabular.get("rows", []):
            values = [str(row.get(h, "")) for h in tabular.get("headers", [])]
            csv_text += ",".join(values) + "\n"
        return {
            "status": "success",
            "format": "csv",
            "output": csv_text,
            "metadata": {
                "total_rows": tabular.get("total_rows", 0),
                "total_entities": tabular.get("total_entities", 0),
            }
        }
    
    elif output_format == "json":
        return {
            "status": "success",
            "format": "json",
            "output": tabular,
            "metadata": {
                "date_range": f"{startDate} to {endDate}",
            }
        }
    
    elif output_format == "stats":
        stats_text = format_stats_summary(tabular)
        return {
            "status": "success",
            "format": "stats",
            "output": stats_text,
        }
    
    else:  # "tabular"
        markdown_text = format_as_markdown_table(tabular)
        stats_text = format_stats_summary(tabular)
        full_output = f"{stats_text}\n\n## üìã DATASET TABULAIRE\n\n{markdown_text}"
        
        return {
            "status": "success",
            "format": "tabular",
            "output": full_output,
            "metadata": {
                "total_rows": tabular.get("total_rows", 0),
                "total_entities": tabular.get("total_entities", 0),
            }
        }


# ========== TOOLS REGISTRATION ==========

@server.list_tools()
async def list_tools() -> list[Tool]:
    return [
        Tool(
            name="get_domains_and_topics",
            description="üåç Liste tous les domaines et topics disponibles. Utilise cet outil en premier.",
            inputSchema={"type": "object", "properties": {}}
        ),
        Tool(
            name="get_visibility_scores",
            description="üìà R√©cup√®re les scores de visibilit√© en dataset tabulaire. Param√®tres optionnels: startDate/endDate (YYYY-MM-DD), models (GLOBAL,gpt-5.1,sonar-pro,google-ai-overview,gpt-interface,gemini-3-pro-preview,gpt-5). Si omis ‚Üí retour complet.",
            inputSchema={
                "type": "object",
                "properties": {
                    "domainId": {"type": "string", "description": "ID du domaine (REQUIS)"},
                    "topicId": {"type": "string", "description": "ID du topic (REQUIS)"},
                    "startDate": {"type": "string", "description": "Date d√©but YYYY-MM-DD (optionnel)"},
                    "endDate": {"type": "string", "description": "Date fin YYYY-MM-DD (optionnel)"},
                    "models": {"type": "string", "description": "Mod√®les √† filtrer (optionnel, s√©par√©s par virgule)"},
                    "output_format": {
                        "type": "string",
                        "enum": ["tabular", "csv", "json", "stats"],
                        "description": "Format de sortie"
                    }
                },
                "required": ["domainId", "topicId"]
            }
        )
    ]


@server.call_tool()
async def call_tool(name: str, arguments: Any) -> list[TextContent]:
    """Ex√©cute un outil"""
    logger.info(f"Calling tool: {name}")
    
    try:
        if name == "get_domains_and_topics":
            res = await get_domains_and_topics()
        elif name == "get_visibility_scores":
            res = await get_visibility_scores(**arguments)
        else:
            raise ValueError(f"Unknown tool: {name}")
        
        output = res.get("output", "")
        if isinstance(output, str):
            return [TextContent(type="text", text=output)]
        else:
            return [TextContent(type="text", text=json.dumps(res, indent=2, default=str))]
    
    except Exception as e:
        logger.error(f"Tool error: {str(e)}", exc_info=True)
        return [TextContent(type="text", text=f"‚ùå Erreur: {str(e)}")]


# ========== CONFIGURATION WEB (SSE + STARLETTE) ==========

sse = SseServerTransport("/messages")


async def handle_sse_connect(request: Request):
    """G√®re la connexion SSE (GET)"""
    logger.info("SSE client connected via GET")
    async with sse.connect_sse(request.scope, request.receive, request._send) as streams:
        await server.run(streams[0], streams[1], server.create_initialization_options())


async def handle_sse_post(request: Request):
    """G√®re les messages SSE (POST)"""
    logger.info("SSE client posting message")
    await sse.handle_post_message(request.scope, request.receive, request._send)


# Routes explicites pour SSE et messages standards
routes = [
    Route("/sse", endpoint=handle_sse_connect, methods=["GET"]),
    Route("/sse", endpoint=handle_sse_post, methods=["POST"]),
    Route("/messages", endpoint=handle_sse_post, methods=["POST"])
]

middleware = [
    Middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_methods=["*"],
        allow_headers=["*"],
    )
]

app = Starlette(debug=True, routes=routes, middleware=middleware)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, log_level="info")