"""
Mint.ai Visibility MCP Server - Version 3.5.0 (Citations Explorer)

Serveur MCP (Model Context Protocol) permettant d'acc√©der aux donn√©es de visibilit√©
de marques via l'API Mint.ai. Compatible avec les clients MCP standards (Claude Desktop)
et les clients Web utilisant le transport SSE (Server-Sent Events).

Fonctionnalit√©s principales:
- R√©cup√©ration de la liste des domaines et topics disponibles
- Extraction des scores de visibilit√© avec historique √©tendu (365 jours par d√©faut)
- Support de multiples mod√®les d'IA (GPT, Gemini, Sonar, etc.)
- Format de donn√©es structur√© pour l'analyse comparative
- R√©cup√©ration des citations pagin√©es avec agr√©gation par domaine source

Modifications version 3.5.0:
- Ajout du tool get_citations : r√©cup√©ration des sources cit√©es par les LLMs dans les prompts
- Agr√©gation automatique : comptage du nombre de mentions par domaine source (moins de lignes)
- Param√®tres de filtrage : mod√®le, cat√©gorie de prompt, pagination

Modifications version 3.4.0:
- Extension de la p√©riode par d√©faut de 30 √† 365 jours d'historique
- Augmentation de la limite de r√©sultats de 100 √† 1000 entr√©es
- Correction de l'erreur 405 sur l'endpoint /sse pour les clients Web

Variables d'environnement requises:
- MINT_API_KEY: Cl√© d'authentification pour l'API Mint.ai
- MINT_BASE_URL: URL de base de l'API (d√©faut: https://api.getmint.ai/api)
"""

import asyncio
import json
import logging
import os
import sys
from datetime import date, timedelta
from typing import Any

import httpx
from mcp.server import Server
from mcp.types import Tool, TextContent
from mcp.server.sse import SseServerTransport

# Imports Starlette & Web
from starlette.applications import Starlette
from starlette.routing import Route
from starlette.middleware import Middleware
from starlette.middleware.cors import CORSMiddleware
from starlette.requests import Request

# ========== CONFIGURATION ==========
# Configuration de l'API Mint.ai via variables d'environnement
# Ces valeurs doivent √™tre d√©finies avant le d√©marrage du serveur
MINT_API_KEY = os.getenv("MINT_API_KEY", "")
MINT_BASE_URL = os.getenv("MINT_BASE_URL", "https://api.getmint.ai/api")

# Configuration du logging pour le suivi des op√©rations et le d√©bogage
# Le niveau INFO permet de suivre les principales actions du serveur
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# V√©rification critique: la cl√© API est indispensable pour toutes les op√©rations
if not MINT_API_KEY:
    logger.warning("MINT_API_KEY environment variable is missing!")

# Cr√©ation de l'instance du serveur MCP avec un nom identifiant unique
server = Server("mint-visibility-mcp")


# ========== LOGIQUE M√âTIER (API & TOOLS) ==========

async def fetch_api(path: str, params: dict = None) -> dict:
    """
    Effectue une requ√™te GET asynchrone vers l'API Mint.ai.
    
    Cette fonction centralise tous les appels √† l'API externe, g√®re l'authentification
    via la cl√© API dans les headers, et propage les erreurs HTTP.
    
    Args:
        path: Chemin de l'endpoint API (ex: "/domains" ou "/domains/{id}/topics")
        params: Dictionnaire optionnel de param√®tres de requ√™te (query parameters)
    
    Returns:
        dict: R√©ponse JSON d√©s√©rialis√©e de l'API
    
    Raises:
        RuntimeError: Si MINT_API_KEY n'est pas d√©finie
        httpx.HTTPStatusError: Si la requ√™te √©choue (4xx, 5xx)
    
    Note:
        Timeout fix√© √† 30 secondes pour √©viter les blocages prolong√©s
    """
    if not MINT_API_KEY:
        raise RuntimeError("MINT_API_KEY environment variable is required")
    async with httpx.AsyncClient() as client:
        response = await client.get(f"{MINT_BASE_URL}{path}", params=params or {}, headers={"X-API-Key": MINT_API_KEY}, timeout=30.0)
        response.raise_for_status()
        return response.json()

async def get_domains_and_topics() -> dict:
    """
    R√©cup√®re la liste compl√®te des domaines et de leurs topics associ√©s depuis l'API Mint.ai.
    
    Cette fonction effectue d'abord une requ√™te pour obtenir tous les domaines disponibles,
    puis pour chaque domaine, r√©cup√®re ses topics associ√©s. Elle construit √©galement un
    mapping pour faciliter la navigation entre domaines et topics.
    
    Returns:
        dict: Dictionnaire structur√© contenant:
            - status: "success" si l'op√©ration r√©ussit
            - data: {
                "domains": Liste compl√®te des domaines avec leurs m√©tadonn√©es
                "topics": Liste de tous les topics avec leur domaine parent
                "mapping": Dict {"{domain} > {topic}": {"domainId": ..., "topicId": ...}}
              }
    
    Note:
        Si la r√©cup√©ration des topics d'un domaine √©choue, l'erreur est ignor√©e
        silencieusement (ligne except: continue) pour ne pas bloquer le traitement
        des autres domaines. Cela pourrait masquer des probl√®mes d'acc√®s ou de permission.
    
    Exemple de mapping g√©n√©r√©:
        {"IBIS > IBIS FR": {"domainId": "694a...", "topicId": "694a..."}}
    """
    # R√©cup√©ration de la liste compl√®te des domaines disponibles
    domains = await fetch_api("/domains")
    all_topics = []
    mapping = {}
    
    # Pour chaque domaine, on r√©cup√®re ses topics associ√©s
    for domain in domains:
        d_id = domain.get("id")
        d_name = domain.get("displayName", domain.get("name", "Unknown"))
        try:
            # Appel API pour obtenir les topics du domaine courant
            topics = await fetch_api(f"/domains/{d_id}/topics")
            for topic in topics:
                t_id = topic.get("id")
                t_name = topic.get("displayName", topic.get("name", "Unknown"))
                
                # Ajout du topic √† la liste globale avec r√©f√©rence au domaine parent
                all_topics.append({"id": t_id, "name": t_name, "domainId": d_id, "domainName": d_name})
                
                # Cr√©ation d'une cl√© de mapping lisible pour faciliter la navigation
                mapping[f"{d_name} > {t_name}"] = {"domainId": d_id, "topicId": t_id}
        except Exception:
            # ATTENTION: Les erreurs sont ignor√©es silencieusement ici
            # Cela peut masquer des probl√®mes d'authentification ou de droits d'acc√®s
            continue
    
    return {"status": "success", "data": {"domains": domains, "topics": all_topics, "mapping": mapping}}

async def get_visibility_scores(domainId: str, topicId: str, startDate: str = None, endDate: str = None, models: str = None) -> dict:
    """
    R√©cup√®re les scores de visibilit√© d'une marque et de ses concurrents sur une p√©riode donn√©e.
    
    Cette fonction constitue le c≈ìur du serveur MCP. Elle interroge l'API Mint.ai pour obtenir
    les donn√©es de visibilit√© agr√©g√©es (score GLOBAL) ainsi que les donn√©es par mod√®le d'IA
    (GPT, Gemini, Sonar, etc.), puis construit un dataset structur√© pour l'analyse.
    
    Args:
        domainId: Identifiant unique du domaine (marque principale)
        topicId: Identifiant unique du topic (segment g√©ographique ou th√©matique)
        startDate: Date de d√©but au format YYYY-MM-DD (optionnel, d√©faut: aujourd'hui - 365 jours)
        endDate: Date de fin au format YYYY-MM-DD (optionnel, d√©faut: aujourd'hui)
        models: Liste de mod√®les sp√©cifiques √† interroger (optionnel, sinon tous les mod√®les)
    
    Returns:
        dict: {
            "status": "success",
            "data": {
                "dataset": Liste de dictionnaires avec structure:
                    {
                        "Date": "YYYY-MM-DD",
                        "EntityName": "Nom de la marque ou du concurrent",
                        "EntityType": "Brand" ou "Competitor",
                        "Score": float (pourcentage de visibilit√©),
                        "Model": "GLOBAL" ou nom du mod√®le IA
                    },
                "metadata": {
                    "models": Liste des mod√®les inclus dans le dataset
                }
            }
        }
    
    Note sur les param√®tres par d√©faut:
        - P√©riode de 365 jours: Permet une analyse de tendances √† long terme
        - Limite de 1000 r√©sultats: Devrait couvrir l'int√©gralit√© des donn√©es pour une ann√©e
        - latestOnly=false: R√©cup√®re toutes les donn√©es historiques, pas seulement le dernier point
    
    Optimisation possible:
        Les appels API par mod√®le sont actuellement s√©quentiels. L'utilisation d'asyncio.gather
        permettrait de parall√©liser ces requ√™tes et d'am√©liorer significativement les performances
        lorsque de nombreux mod√®les sont disponibles.
    """
    # Si aucune date n'est sp√©cifi√©e, on utilise les 365 derniers jours par d√©faut
    # Cette p√©riode √©tendue (vs 30 jours en v3.3.0) permet des analyses de tendances robustes
    if not startDate or not endDate:
        endDate = date.today().strftime("%Y-%m-%d")
        startDate = (date.today() - timedelta(days=365)).strftime("%Y-%m-%d")
    
    # Param√®tres de base pour toutes les requ√™tes API
    # - latestOnly=false: R√©cup√®re l'historique complet, pas seulement le dernier snapshot
    # - page=1: Pagination (non utilis√©e actuellement, mais pourrait √™tre impl√©ment√©e)
    # - limit=1000: Nombre maximum de points de donn√©es (augment√© de 100 √† 1000 en v3.4.0)
    base_params = {"startDate": startDate, "endDate": endDate, "latestOnly": "false", "page": "1", "limit": "1000"}
    
    # R√©cup√©ration des donn√©es agr√©g√©es GLOBAL (tous mod√®les confondus)
    # Cette requ√™te retourne √©galement la liste des mod√®les disponibles pour ce domaine/topic
    global_data = await fetch_api(f"/domains/{domainId}/topics/{topicId}/visibility/aggregated", base_params)
    available_models = global_data.get("availableModels", [])
    
    # R√©cup√©ration des donn√©es par mod√®le individuel (GPT-5, Gemini, Sonar, etc.)
    # ATTENTION: Cette boucle effectue des appels s√©quentiels qui pourraient √™tre parall√©lis√©s
    # avec asyncio.gather pour am√©liorer les performances
    by_model_data = {}
    for m in available_models:
        try:
            # Pour chaque mod√®le, on refait un appel avec le filtre "models" sp√©cifique
            by_model_data[m] = await fetch_api(f"/domains/{domainId}/topics/{topicId}/visibility/aggregated", {**base_params, "models": m})
        except:
            # Les erreurs sont ignor√©es silencieusement pour √©viter qu'un mod√®le d√©faillant
            # ne bloque l'int√©gralit√© de la r√©cup√©ration. Cependant, cela masque les probl√®mes.
            pass

    # Construction du dataset unifi√© au format structur√©
    # Chaque ligne repr√©sente un score (marque ou concurrent) √† une date donn√©e pour un mod√®le
    dataset = []
    
    def add_rows(data, model_name):
        """
        Fonction interne pour transformer les donn√©es chartData de l'API en lignes de dataset.
        
        Structure de chartData de l'API:
        [
            {
                "date": "2026-01-13",
                "brand": 50.76,
                "competitors": {"Booking": 30, "B&B Hotels": 26, ...}
            },
            ...
        ]
        
        Transformation en dataset:
        - Une ligne pour la marque principale
        - Une ligne pour chaque concurrent
        - Toutes li√©es √† la m√™me date et au m√™me mod√®le
        """
        for entry in data.get("chartData", []):
            d = entry.get("date")
            # Ajout du score de la marque principale
            dataset.append({"Date": d, "EntityName": "Brand", "EntityType": "Brand", "Score": entry.get("brand"), "Model": model_name})
            # Ajout des scores de tous les concurrents pour cette date
            for c_name, c_score in entry.get("competitors", {}).items():
                dataset.append({"Date": d, "EntityName": c_name, "EntityType": "Competitor", "Score": c_score, "Model": model_name})

    # Ajout des donn√©es GLOBAL (agr√©g√©es tous mod√®les)
    add_rows(global_data, "GLOBAL")
    
    # Ajout des donn√©es par mod√®le individuel
    for m, data in by_model_data.items():
        add_rows(data, m)

    return {"status": "success", "data": {"dataset": dataset, "metadata": {"models": ["GLOBAL"] + available_models}}}


async def get_citations(
    domainId: str,
    topicId: str,
    startDate: str = None,
    endDate: str = None,
    models: str = None,
) -> dict:
    """
    R√©cup√®re les top domaines et top URLs cit√©s pour un topic donn√©,
    en bouclant sur chaque mod√®le disponible (m√™me logique que get_visibility_scores).

    Utilise l'endpoint visibility/aggregated avec includeDetailedResults=true
    qui retourne directement topDomains, topCitedUrls, topDomainsOverTime, etc.
    ‚Üí Pas de pagination, 1 seul call par mod√®le.

    Args:
        domainId:   ID du domaine (REQUIS)
        topicId:    ID du topic (REQUIS)
        startDate:  Date d√©but YYYY-MM-DD (d√©faut: aujourd'hui - 90j)
        endDate:    Date fin   YYYY-MM-DD (d√©faut: aujourd'hui)
        models:     Mod√®les √† inclure, s√©par√©s par virgule (optionnel, d√©faut: tous)

    Returns:
        dict avec :
          - top_domains  : [{Model, Domain, CitationCount, Rank}, ...]
          - top_urls     : [{Model, Url, Domain, CitationCount, Rank}, ...]
          - domains_over_time : [{Model, Date, Domain, Count}, ...]
          - urls_over_time    : [{Model, Date, Url, Count}, ...]
          - global_metrics    : [{Model, TotalPrompts, TotalAnswers, TotalCitations, ReportCount}, ...]
    """
    if not startDate or not endDate:
        endDate   = date.today().strftime("%Y-%m-%d")
        startDate = (date.today() - timedelta(days=90)).strftime("%Y-%m-%d")

    base_params = {
        "startDate":              startDate,
        "endDate":                endDate,
        "includeDetailedResults": "true",
        "latestOnly":             "false",
        "page":                   "1",
        "limit":                  "1000",  # max pour r√©cup√©rer tous les top domaines/URLs sans troncature
    }

    endpoint = f"/domains/{domainId}/topics/{topicId}/visibility/aggregated"

    # ‚îÄ‚îÄ R√©cup√©ration GLOBAL + liste des mod√®les disponibles ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    global_data      = await fetch_api(endpoint, base_params)
    available_models = global_data.get("availableModels", [])

    # Filtre optionnel sur les mod√®les
    if models:
        requested = [m.strip() for m in models.split(",")]
        available_models = [m for m in available_models if m in requested]

    # ‚îÄ‚îÄ R√©cup√©ration par mod√®le en parall√®le ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    async def fetch_model(m):
        try:
            return m, await fetch_api(endpoint, {**base_params, "models": m})
        except Exception:
            return m, None

    tasks = [fetch_model(m) for m in available_models]
    model_results = await asyncio.gather(*tasks)
    by_model = {m: d for m, d in model_results if d is not None}

    # ‚îÄ‚îÄ Extraction helper ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    def extract(data, model_name):
        top_domains, top_urls, domains_ot, urls_ot, metrics = [], [], [], [], []

        # topDomains
        for i, item in enumerate(data.get("topDomains", []), 1):
            top_domains.append({
                "Model":         model_name,
                "Domain":        item.get("domain", item.get("linkDomain", "")),
                "CitationCount": item.get("count",  item.get("citationCount", 0)),
                "Rank":          i,
            })

        # topCitedUrls
        for i, item in enumerate(data.get("topCitedUrls", []), 1):
            top_urls.append({
                "Model":         model_name,
                "Url":           item.get("url",    item.get("link", "")),
                "Domain":        item.get("domain", item.get("linkDomain", "")),
                "CitationCount": item.get("count",  item.get("citationCount", 0)),
                "Rank":          i,
            })

        # topDomainsOverTime
        for entry in data.get("topDomainsOverTime", []):
            for domain, count in entry.get("domains", {}).items():
                domains_ot.append({
                    "Model":  model_name,
                    "Date":   entry.get("date", ""),
                    "Domain": domain,
                    "Count":  count,
                })

        # topUrlsOverTime
        for entry in data.get("topUrlsOverTime", []):
            for url, count in entry.get("urls", {}).items():
                urls_ot.append({
                    "Model": model_name,
                    "Date":  entry.get("date", ""),
                    "Url":   url,
                    "Count": count,
                })

        # global metrics
        metrics.append({
            "Model":         model_name,
            "TotalPrompts":  data.get("totalPromptsTested", 0),
            "TotalAnswers":  data.get("totalAnswers",        0),
            "TotalCitations":data.get("totalCitations",     0),
            "ReportCount":   data.get("reportCount",        0),
        })

        return top_domains, top_urls, domains_ot, urls_ot, metrics

    # ‚îÄ‚îÄ Assemblage du dataset final ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    all_top_domains, all_top_urls, all_domains_ot, all_urls_ot, all_metrics = [], [], [], [], []

    # GLOBAL d'abord
    td, tu, dot, uot, met = extract(global_data, "GLOBAL")
    all_top_domains  += td;  all_top_urls    += tu
    all_domains_ot   += dot; all_urls_ot     += uot
    all_metrics      += met

    # Puis chaque mod√®le
    for m, data in by_model.items():
        td, tu, dot, uot, met = extract(data, m)
        all_top_domains  += td;  all_top_urls    += tu
        all_domains_ot   += dot; all_urls_ot     += uot
        all_metrics      += met

    return {
        "status": "success",
        "data": {
            "top_domains":      all_top_domains,
            "top_urls":         all_top_urls,
            "domains_over_time":all_domains_ot,
            "urls_over_time":   all_urls_ot,
            "global_metrics":   all_metrics,
            "metadata": {
                "models": ["GLOBAL"] + list(by_model.keys()),
                "startDate": startDate,
                "endDate":   endDate,
            },
        },
    }

# ========== ENREGISTREMENT DES OUTILS MCP ==========

@server.list_tools()
async def list_tools() -> list[Tool]:
    """
    D√©clare la liste des outils (tools) disponibles dans ce serveur MCP.
    
    Cette fonction est appel√©e automatiquement par le client MCP lors de la connexion
    pour d√©couvrir les capacit√©s du serveur. Chaque outil d√©clar√© ici devient accessible
    via l'interface call_tool().
    
    Returns:
        list[Tool]: Liste des outils MCP avec leurs sch√©mas de validation
    
    Outils disponibles:
        1. get_domains_and_topics: Exploration de la hi√©rarchie domaines/topics
        2. get_visibility_scores: R√©cup√©ration des donn√©es de visibilit√© avec historique
    """
    return [
        Tool(
            name="get_domains_and_topics",
            description="üåç Liste tous les domaines et topics disponibles. Utilise cet outil en premier.",
            inputSchema={"type": "object", "properties": {}}
        ),
        Tool(
            name="get_visibility_scores",
            description="üìà R√©cup√®re les scores de visibilit√© en dataset tabulaire. Param√®tres optionnels: startDate/endDate (YYYY-MM-DD), models (GLOBAL,gpt-5.1,sonar-pro,google-ai-overview,gpt-interface,gemini-3-pro-preview,gpt-5). Si omis ‚Üí retour complet.",
            inputSchema={
                "type": "object",
                "properties": {
                    "domainId": {"type": "string", "description": "ID du domaine (REQUIS)"},
                    "topicId": {"type": "string", "description": "ID du topic (REQUIS)"},
                    "startDate": {"type": "string", "description": "Date d√©but YYYY-MM-DD (optionnel)"},
                    "endDate": {"type": "string", "description": "Date fin YYYY-MM-DD (optionnel)"},
                    "models": {"type": "string", "description": "Mod√®les √† filtrer (optionnel, s√©par√©s par virgule)"}
                },
                "required": ["domainId", "topicId"]
            }
        ),
        Tool(
            name="get_citations",
            description="üîó R√©cup√®re les top domaines et top URLs cit√©s par les LLMs, par mod√®le. Boucle sur tous les mod√®les disponibles (GLOBAL + GPT-5, Gemini, Sonar...). Retourne: top_domains, top_urls, domains_over_time, urls_over_time, global_metrics. Param√®tres optionnels: startDate/endDate (YYYY-MM-DD, d√©faut 90j), models (s√©par√©s par virgule).",
            inputSchema={
                "type": "object",
                "properties": {
                    "domainId":  {"type": "string", "description": "ID du domaine (REQUIS)"},
                    "topicId":   {"type": "string", "description": "ID du topic (REQUIS)"},
                    "startDate": {"type": "string", "description": "Date d√©but YYYY-MM-DD (optionnel, d√©faut: aujourd'hui - 90 jours)"},
                    "endDate":   {"type": "string", "description": "Date fin YYYY-MM-DD (optionnel, d√©faut: aujourd'hui)"},
                    "models":    {"type": "string", "description": "Mod√®les √† inclure, s√©par√©s par virgule (optionnel, d√©faut: tous)"},
                },
                "required": ["domainId", "topicId"]
            }
        )
    ]

@server.call_tool()
async def call_tool(name: str, arguments: Any) -> list[TextContent]:
    """
    Point d'entr√©e pour l'ex√©cution des outils MCP.
    
    Cette fonction est appel√©e par le client MCP lorsqu'il souhaite ex√©cuter un outil.
    Elle route la demande vers la fonction appropri√©e et g√®re les erreurs de mani√®re centralis√©e.
    
    Args:
        name: Nom de l'outil √† ex√©cuter (doit correspondre √† un outil d√©clar√© dans list_tools)
        arguments: Dictionnaire d'arguments pass√©s √† l'outil (valid√©s selon le inputSchema)
    
    Returns:
        list[TextContent]: R√©ponse encapsul√©e au format MCP (JSON s√©rialis√© en texte)
    
    Gestion des erreurs:
        Toutes les exceptions sont captur√©es et retourn√©es sous forme de message d'erreur textuel.
        ATTENTION: Cette approche masque les d√©tails des erreurs. Une gestion plus granulaire
        permettrait de distinguer les erreurs d'authentification, de validation, de r√©seau, etc.
    """
    try:
        # Routage vers la fonction appropri√©e selon le nom de l'outil
        if name == "get_domains_and_topics":
            res = await get_domains_and_topics()
        elif name == "get_visibility_scores":
            # Expansion des arguments du dictionnaire comme param√®tres nomm√©s
            res = await get_visibility_scores(**arguments)
        elif name == "get_citations":
            res = await get_citations(**arguments)
        else:
            raise ValueError(f"Unknown tool: {name}")
        
        # S√©rialisation de la r√©ponse en JSON, avec gestion des types non-standard (dates, etc.)
        return [TextContent(type="text", text=json.dumps(res, default=str))]
    except Exception as e:
        # AM√âLIORATION POSSIBLE: Distinguer les types d'erreurs pour des messages plus pr√©cis
        # - AuthenticationError ‚Üí "Cl√© API invalide ou expir√©e"
        # - ValidationError ‚Üí "Param√®tres invalides: {d√©tails}"
        # - NetworkError ‚Üí "Impossible de joindre l'API Mint.ai"
        return [TextContent(type="text", text=f"Error: {str(e)}")]


# ========== CONFIGURATION WEB (TRANSPORT SSE & ROUTING) ==========

# Cr√©ation du transport SSE (Server-Sent Events) pour la communication MCP
# L'endpoint /messages est la route standard pour les clients MCP stricts (Claude Desktop)
sse = SseServerTransport("/messages")

async def handle_sse_connect(request: Request):
    """
    G√®re la connexion initiale SSE (requ√™te GET).
    
    Cette fonction est appel√©e lorsqu'un client MCP √©tablit une connexion SSE.
    Elle cr√©e les streams de communication bidirectionnels et lance la boucle
    principale du serveur MCP pour traiter les messages entrants.
    
    Args:
        request: Requ√™te HTTP Starlette contenant scope, receive et send
    
    Note:
        Cette fonction reste active pendant toute la dur√©e de la session MCP.
        Elle ne se termine que lorsque le client ferme la connexion.
    """
    async with sse.connect_sse(request.scope, request.receive, request._send) as streams:
        # D√©marrage de la boucle principale du serveur MCP avec les streams de communication
        await server.run(streams[0], streams[1], server.create_initialization_options())

async def handle_messages(request: Request):
    """
    G√®re les messages entrants (requ√™te POST).
    
    Cette fonction traite les messages JSON-RPC envoy√©s par le client MCP via POST.
    Elle est appel√©e pour chaque invocation d'outil ou requ√™te du client apr√®s
    l'√©tablissement de la connexion SSE initiale.
    
    Args:
        request: Requ√™te HTTP POST contenant le message JSON-RPC
    """
    await sse.handle_post_message(request.scope, request.receive, request._send)

# ========== D√âFINITION DES ROUTES HTTP ==========
# 
# Configuration critique pour la compatibilit√© multi-clients:
# - Claude Desktop et clients MCP stricts utilisent /messages (GET + POST)
# - Certains clients Web et interfaces custom utilisent /sse (GET + POST)
# 
# Le probl√®me r√©solu ici (version 3.3.0):
# Avant, seul GET √©tait configur√© sur /sse, causant des erreurs 405 (Method Not Allowed)
# lorsque des clients Web tentaient de POST des messages sur cet endpoint.
# 
# Solution: D√©finir explicitement GET et POST sur les deux endpoints (/sse et /messages)

routes = [
    # Endpoint /sse pour les clients Web et interfaces custom
    Route("/sse", endpoint=handle_sse_connect, methods=["GET"]),   # Connexion SSE initiale
    Route("/sse", endpoint=handle_messages, methods=["POST"]),      # Messages JSON-RPC (FIX v3.3.0)
    
    # Endpoint /messages pour les clients MCP stricts (standard du protocole)
    Route("/messages", endpoint=handle_messages, methods=["POST"])  # Messages JSON-RPC
]

# Configuration CORS (Cross-Origin Resource Sharing)
# Permet l'acc√®s au serveur depuis n'importe quelle origine (d√©veloppement/production)
# S√âCURIT√â: En production, il serait recommand√© de restreindre allow_origins
# √† une liste explicite de domaines autoris√©s plut√¥t que d'utiliser "*"
middleware = [
    Middleware(
        CORSMiddleware,
        allow_origins=["*"],        # ATTENTION: Accepte toutes les origines (permissif)
        allow_methods=["*"],        # Autorise tous les verbes HTTP
        allow_headers=["*"],        # Autorise tous les headers
    )
]

# Cr√©ation de l'application Starlette avec la configuration compl√®te
# - debug=True: Active le mode d√©bogage (√† d√©sactiver en production)
# - routes: Configuration des endpoints HTTP
# - middleware: Stack de middlewares (CORS uniquement pour l'instant)
app = Starlette(debug=True, routes=routes, middleware=middleware)