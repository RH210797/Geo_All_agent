"""
Mint.ai Visibility MCP Server - Version 3.5.2 (LLM Guidance Advanced)

Ce serveur MCP retourne des DATASETS TABULAIRES lisibles.
Les commentaires d√©taill√©s ci-dessous guident le LLM sur TOUS les param√®tres,
en particulier les param√®tres OPTIONNELS (dates, models).

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
GUIDE COMPLET POUR LE LLM:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

1Ô∏è‚É£ CHERCHER UN DOMAINE/TOPIC?
   ‚Üí Utilise d'abord: get_domains_and_topics()
   ‚Üí Cela retourne la liste des IDs disponibles + mapping
   ‚Üí Exemple: "IBIS France" ‚Üí domainId: "694a6c9c..." + topicId: "694a6d61..."

2Ô∏è‚É£ ANALYSER LA VISIBILIT√â?
   ‚Üí Utilise: get_visibility_scores(domainId, topicId, output_format="tabular")
   ‚Üí Cela retourne une BELLE TABLE avec:
      - Lignes: Date + Model
      - Colonnes: Brand + Competitors
      - Stats: Moyenne, Min, Max par entit√©

3Ô∏è‚É£ PARAM√àTRES DE DATES (OPTIONNELS) ‚ö†Ô∏è TR√àS IMPORTANT!
   
   SC√âNARIO 1: L'utilisateur NE MENTIONNE PAS DE DATES
   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   Exemple user: "Analyse IBIS France" (pas de dates mentionn√©es)
   ‚Üí NE PASSE PAS startDate ni endDate
   ‚Üí Le serveur retourne TOUTES LES DONN√âES DISPONIBLES ‚úÖ
   ‚Üí Comportement: Cherche la plus ancienne jusqu'√† aujourd'hui
   ‚Üí Avantage: Vue compl√®te historique
   
   SC√âNARIO 2: L'utilisateur MENTIONNE UNE PLAGE
   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   Exemple user: "Donn√©es de d√©cembre 2025"
   ‚Üí Calcule automatiquement:
      startDate="2025-12-01", endDate="2025-12-31"
   ‚Üí Format: "YYYY-MM-DD" (ex: "2025-12-15")
   
   SC√âNARIO 3: L'utilisateur DEMANDE LES 30 DERNIERS JOURS
   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   Exemple user: "Montre les 30 derniers jours"
   ‚Üí Calcule automatiquement:
      endDate = aujourd'hui (ex: "2026-02-10")
      startDate = aujourd'hui - 30 jours (ex: "2026-01-11")
   
   SC√âNARIO 4: L'utilisateur DEMANDE TOUT
   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   Exemple user: "Montre-moi tous les donn√©es", "Tout depuis le d√©but"
   ‚Üí NE PASSE PAS startDate ni endDate
   ‚Üí Retour: Toutes les donn√©es disponibles ‚úÖ
   
   ‚ö° R√àGLE D'OR: Si pas de dates mentionn√©es ‚Üí OMETS les param√®tres!

4Ô∏è‚É£ PARAM√àTRE MODELS (OPTIONNEL) ‚ö†Ô∏è TR√àS IMPORTANT!
   
   MOD√àLES DISPONIBLES (7 au total, tous compatibles):
   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   
   Pour analyser les SCORES:
   ‚îú‚îÄ "GLOBAL"                    ‚Üê Score COMBIN√â (recommand√©, d√©faut)
   ‚îÇ  Utilise: Tous les mod√®les
   ‚îÇ  Cas d'usage: Analyse g√©n√©rale, comparaison fiable
   ‚îÇ
   ‚îú‚îÄ "gpt-5.1"                   ‚Üê Model OpenAI GPT-5.1 (nouvelle)
   ‚îÇ  Cas d'usage: R√©sultats OpenAI, comparaison avec GPT-5
   ‚îÇ
   ‚îú‚îÄ "sonar-pro"                 ‚Üê Model Perplexity Sonar Pro
   ‚îÇ  Cas d'usage: R√©sultats Perplexity, recherche avanc√©e
   ‚îÇ
   ‚îú‚îÄ "google-ai-overview"        ‚Üê Google AI Overview
   ‚îÇ  Cas d'usage: R√©sultats Google, AI Overview int√©gr√©
   ‚îÇ
   ‚îú‚îÄ "gpt-interface"             ‚Üê GPT Interface (ancienne)
   ‚îÇ  Cas d'usage: R√©sultats legacy, comparaison historique
   ‚îÇ
   ‚îú‚îÄ "gemini-3-pro-preview"      ‚Üê Google Gemini 3 Pro Preview
   ‚îÇ  Cas d'usage: R√©sultats Gemini, preview functionality
   ‚îÇ
   ‚îî‚îÄ "gpt-5"                     ‚Üê Model OpenAI GPT-5 (flagship)
      Cas d'usage: R√©sultats OpenAI premium, benchmark
   
   SC√âNARIO 1: L'utilisateur NE MENTIONNE PAS DE MOD√àLE
   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   Exemple user: "Analyse IBIS France" (pas de mod√®le mentionn√©)
   ‚Üí NE PASSE PAS le param√®tre 'models'
   ‚Üí Le serveur retourne TOUS LES MOD√àLES ‚úÖ
   ‚Üí R√©sultat: Table avec lignes pour chaque (date, model) combo
   ‚Üí Avantage: Voir l'√©volution sur TOUS les mod√®les
   
   SC√âNARIO 2: L'utilisateur DEMANDE UN SEUL MOD√àLE
   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   Exemple user: "Montre-moi les scores GPT-5.1"
   ‚Üí Passe: models="gpt-5.1"
   ‚Üí R√©sultat: Table filtr√©e sur GPT-5.1 uniquement
   
   SC√âNARIO 3: L'utilisateur DEMANDE PLUSIEURS MOD√àLES
   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   Exemple user: "Compare GPT-5.1, Sonar Pro et Gemini"
   ‚Üí Passe: models="gpt-5.1,sonar-pro,gemini-3-pro-preview"
   ‚Üí Format: S√©par√©s par virgules, SANS espaces
   ‚Üí R√©sultat: Table avec ces 3 mod√®les + GLOBAL
   
   SC√âNARIO 4: L'utilisateur DEMANDE LE GLOBAL
   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   Exemple user: "Juste le score global combin√©"
   ‚Üí Passe: models="GLOBAL"
   ‚Üí R√©sultat: Table avec GLOBAL uniquement (le plus rapide)
   
   ‚ö° R√àGLE D'OR: 
      - Pas de mention ‚Üí OMETS le param√®tre ‚Üí TOUS les mod√®les
      - Mentionne un mod√®le ‚Üí Passe ce mod√®le
      - Mentionne plusieurs ‚Üí Passe tous (s√©par√©s par virgule)

5Ô∏è‚É£ COMBINAISON: DATES + MODELS
   
   EXEMPLE COMPLET:
   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   User: "Montre-moi le GLOBAL pour les 7 derniers jours"
   
   ‚Üí Calcule dates:
      endDate = aujourd'hui (ex: "2026-02-10")
      startDate = 7 jours avant (ex: "2026-02-03")
   
   ‚Üí Filtre mod√®le:
      models = "GLOBAL"
   
   ‚Üí Appel:
      get_visibility_scores(
        domainId="...",
        topicId="...",
        startDate="2026-02-03",
        endDate="2026-02-10",
        models="GLOBAL",
        output_format="tabular"
      )

6Ô∏è‚É£ FORMAT DE SORTIE?
   
   Quatre options disponibles:
   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
   
   "tabular" (D√âFAUT)
   ‚Üí Table Markdown lisible + stats auto-calcul√©es
   ‚Üí Meilleur pour: Analyse humaine, rapports
   ‚Üí Temps: Normal
   
   "csv"
   ‚Üí Format CSV pur (copier-coller dans Excel)
   ‚Üí Meilleur pour: Export Excel/Sheets
   ‚Üí Temps: Normal
   
   "json"
   ‚Üí JSON structur√© (headers, rows, stats, metadata)
   ‚Üí Meilleur pour: Int√©gration code, traitement automatis√©
   ‚Üí Temps: Normal
   
   "stats"
   ‚Üí Synth√®se stats uniquement (Moy/Min/Max par entit√©)
   ‚Üí Meilleur pour: Vue rapide, comparaisons
   ‚Üí Temps: ‚ö° 5x plus rapide que tabular

7Ô∏è‚É£ INTERPR√âTER LES R√âSULTATS?
   ‚Üí Cherche d'abord le R√âSUM√â PAR ENTIT√â (stats)
   ‚Üí Puis analyse le DATASET TABULAIRE (tendances)
   ‚Üí Colonnes = Brand + Competitors (comparer visibilit√©)
   ‚Üí Lignes = Dates + Models (voir √©volutions)

8Ô∏è‚É£ CAS D'USAGE RAPIDES:
   
   "Analyse compl√®te une r√©gion"
   ‚Üí Omets dates, mod√®les, format="tabular" (d√©faut)
   ‚Üí get_visibility_scores(domainId, topicId)
   
   "Vue rapide (synth√®se)"
   ‚Üí Omets dates, mod√®les, format="stats"
   ‚Üí get_visibility_scores(domainId, topicId, output_format="stats")
   
   "Compare GPT-5.1 vs Gemini"
   ‚Üí models="gpt-5.1,gemini-3-pro-preview"
   ‚Üí get_visibility_scores(domainId, topicId, models="gpt-5.1,gemini-3-pro-preview")
   
   "7 derniers jours, GLOBAL seulement"
   ‚Üí models="GLOBAL", calcule dates (-7j)
   ‚Üí get_visibility_scores(domainId, topicId, startDate="...", endDate="...", models="GLOBAL")
   
   "Export Excel aujourd'hui"
   ‚Üí output_format="csv"
   ‚Üí get_visibility_scores(domainId, topicId, output_format="csv")

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
R√âSUM√â DES PARAM√àTRES:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

PARAM√àTRE      | TYPE        | OPTIONNEL | D√âFAUT           | NOTES
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
domainId       | string      | ‚ùå REQUIS | N/A              | De get_domains()
topicId        | string      | ‚ùå REQUIS | N/A              | De get_domains()
startDate      | YYYY-MM-DD  | ‚úÖ OPT   | Anciennement     | Si omis: tout
endDate        | YYYY-MM-DD  | ‚úÖ OPT   | Aujourd'hui      | Si omis: tout
models         | string      | ‚úÖ OPT   | TOUS les mod√®les | S√©par√©s par ,
output_format  | string      | ‚úÖ OPT   | "tabular"        | tabular/csv/json/stats

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
"""

import asyncio
import json
import logging
import os
import sys
from datetime import date, timedelta
from typing import Any
from collections import defaultdict

import httpx
from mcp.server import Server
from mcp.types import Tool, TextContent
from mcp.server.sse import SseServerTransport

# Imports Starlette & Web
from starlette.applications import Starlette
from starlette.routing import Route
from starlette.middleware import Middleware
from starlette.middleware.cors import CORSMiddleware
from starlette.requests import Request

# Configuration
MINT_API_KEY = os.getenv("MINT_API_KEY", "")
MINT_BASE_URL = os.getenv("MINT_BASE_URL", "https://api.getmint.ai/api")

# Mod√®les disponibles (pour le LLM)
AVAILABLE_MODELS = [
    "GLOBAL",                    # Score combin√© (d√©faut)
    "gpt-5.1",                  # OpenAI GPT-5.1
    "sonar-pro",                # Perplexity Sonar Pro
    "google-ai-overview",       # Google AI Overview
    "gpt-interface",            # GPT Interface
    "gemini-3-pro-preview",     # Google Gemini 3 Pro
    "gpt-5"                     # OpenAI GPT-5
]

# Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

if not MINT_API_KEY:
    logger.warning("MINT_API_KEY environment variable is missing!")

# Cr√©ation du serveur MCP
server = Server("mint-visibility-mcp")


# ========== UTILITAIRES POUR DATASET TABULAIRE ==========

def create_tabular_dataset(raw_dataset: list[dict]) -> dict:
    """
    üîß FONCTION CL√âE: Transforme le dataset brut en PIVOT TABLE structur√©
    
    Entr√©e:
      - raw_dataset: liste de dicts avec Date, EntityName, Score, Model
    
    Sortie:
      - Dataset pivott√© avec:
        * headers: ["Date", "Model", "Brand", "Competitor1", "Competitor2", ...]
        * rows: Liste de dicts (une ligne = une date+model)
        * entities: Liste des entit√©s (Brand + Competitors)
        * stats: Statistiques par entit√© (Moy, Min, Max, Count)
    """
    if not raw_dataset:
        return {"error": "Aucune donn√©e"}
    
    # √âtape 1: Grouper par (date, model)
    pivot_data = {}
    all_entities = set()
    
    for row in raw_dataset:
        date_val = row.get("Date", "")
        model_val = row.get("Model", "")
        entity = row.get("EntityName", "")
        score = row.get("Score", 0)
        
        all_entities.add(entity)
        key = f"{date_val}|{model_val}"
        
        if key not in pivot_data:
            pivot_data[key] = {"Date": date_val, "Model": model_val}
        
        pivot_data[key][entity] = round(score, 2) if isinstance(score, (int, float)) else 0
    
    # √âtape 2: Trier les entit√©s (Brand d'abord)
    all_entities = list(all_entities)
    if "Brand" in all_entities:
        all_entities.remove("Brand")
        all_entities = ["Brand"] + sorted(all_entities)
    
    headers = ["Date", "Model"] + all_entities
    
    # √âtape 3: Construire les lignes
    rows = []
    for key in sorted(pivot_data.keys()):
        row = {"Date": pivot_data[key]["Date"], "Model": pivot_data[key]["Model"]}
        for entity in all_entities:
            row[entity] = pivot_data[key].get(entity, None)
        rows.append(row)
    
    # √âtape 4: Calculer stats
    stats = {}
    for entity in all_entities:
        scores = [r[entity] for r in rows if r[entity] is not None]
        if scores:
            stats[entity] = {
                "average": round(sum(scores) / len(scores), 2),
                "min": round(min(scores), 2),
                "max": round(max(scores), 2),
                "count": len(scores)
            }
    
    return {
        "headers": headers,
        "rows": rows,
        "entities": all_entities,
        "stats": stats,
        "total_rows": len(rows),
        "total_entities": len(all_entities)
    }

def format_as_markdown_table(tabular_data: dict) -> str:
    """üìä Formate le dataset tabulaire en TABLE MARKDOWN lisible"""
    if "error" in tabular_data:
        return f"‚ùå {tabular_data['error']}"
    
    headers = tabular_data.get("headers", [])
    rows = tabular_data.get("rows", [])
    
    if not rows:
        return "‚ùå Aucune donn√©e √† afficher"
    
    md = "| " + " | ".join(headers) + " |\n"
    md += "|" + "|".join([":---" for _ in headers]) + "|\n"
    
    for row in rows:
        values = []
        for h in headers:
            val = row.get(h)
            if val is None:
                values.append("-")
            elif isinstance(val, float):
                values.append(f"{val:.2f}%")
            else:
                values.append(str(val))
        md += "| " + " | ".join(values) + " |\n"
    
    return md

def format_as_csv(tabular_data: dict) -> str:
    """üìã Formate le dataset en CSV exploitable"""
    if "error" in tabular_data:
        return f"Error: {tabular_data['error']}"
    
    headers = tabular_data.get("headers", [])
    rows = tabular_data.get("rows", [])
    
    if not rows:
        return "No data"
    
    csv = ",".join(headers) + "\n"
    
    for row in rows:
        values = []
        for h in headers:
            val = row.get(h)
            if val is None:
                values.append("")
            elif isinstance(val, float):
                values.append(f"{val:.2f}")
            else:
                values.append(str(val))
        csv += ",".join(values) + "\n"
    
    return csv

def format_stats_summary(tabular_data: dict) -> str:
    """üìä G√©n√®re un R√âSUM√â DES STATS lisible"""
    if "error" in tabular_data:
        return f"‚ùå {tabular_data['error']}"
    
    stats = tabular_data.get("stats", {})
    if not stats:
        return "‚ùå Aucune statistique"
    
    summary = "## üìä STATISTIQUES PAR ENTIT√â\n\n"
    summary += "| Entit√© | Moyenne | Min | Max | Mesures |\n"
    summary += "|--------|---------|-----|-----|----------|\n"
    
    for entity in sorted(stats.keys()):
        s = stats[entity]
        summary += f"| {entity} | {s['average']:.2f}% | {s['min']:.2f}% | {s['max']:.2f}% | {s['count']} |\n"
    
    return summary


# ========== LOGIQUE M√âTIER (API & TOOLS) ==========

async def fetch_api(path: str, params: dict = None) -> dict:
    """üîó Appel API vers Mint.ai"""
    if not MINT_API_KEY:
        raise RuntimeError("MINT_API_KEY environment variable is required")
    async with httpx.AsyncClient() as client:
        response = await client.get(
            f"{MINT_BASE_URL}{path}", 
            params=params or {}, 
            headers={"X-API-Key": MINT_API_KEY}, 
            timeout=30.0
        )
        response.raise_for_status()
        return response.json()

async def get_domains_and_topics() -> dict:
    """üåç OUTIL #1: Liste les domaines et topics disponibles"""
    domains = await fetch_api("/domains")
    all_topics = []
    mapping = {}
    for domain in domains:
        d_id = domain.get("id")
        d_name = domain.get("displayName", domain.get("name", "Unknown"))
        try:
            topics = await fetch_api(f"/domains/{d_id}/topics")
            for topic in topics:
                t_id = topic.get("id")
                t_name = topic.get("displayName", topic.get("name", "Unknown"))
                all_topics.append({
                    "id": t_id, 
                    "name": t_name, 
                    "domainId": d_id, 
                    "domainName": d_name
                })
                mapping[f"{d_name} > {t_name}"] = {
                    "domainId": d_id, 
                    "topicId": t_id
                }
        except Exception: 
            continue
    
    return {
        "status": "success", 
        "data": {
            "domains": domains, 
            "topics": all_topics, 
            "mapping": mapping
        }
    }

async def get_visibility_scores(
    domainId: str, 
    topicId: str, 
    startDate: str = None, 
    endDate: str = None, 
    models: str = None,
    output_format: str = "tabular"
) -> dict:
    """
    üìà OUTIL #2: R√©cup√®re les scores de visibilit√© en dataset TABULAIRE
    
    ‚ö†Ô∏è PARAM√àTRES OPTIONNELS - TR√àS IMPORTANT POUR LE LLM:
    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    startDate (OPTIONNEL):
      - Si OMIS ‚Üí Retourne TOUTES les donn√©es disponibles ‚úÖ
      - Si FOURNI ‚Üí Format "YYYY-MM-DD" (ex: "2025-12-23")
      - Cas courant: User dit "30 derniers jours" ‚Üí calcule automatiquement
      - R√®gle: SI user ne mentionne PAS de dates ‚Üí OMETS ce param√®tre
    
    endDate (OPTIONNEL):
      - Si OMIS ‚Üí Retourne jusqu'√† aujourd'hui/pr√©sent ‚úÖ
      - Si FOURNI ‚Üí Format "YYYY-MM-DD" (ex: "2026-02-10")
      - Rarement utilis√© seul (avec startDate g√©n√©ralement)
      - R√®gle: SI user ne mentionne PAS de dates ‚Üí OMETS ce param√®tre
    
    models (OPTIONNEL):
      - Si OMIS ‚Üí Retourne TOUS les mod√®les disponibles ‚úÖ
      - Si FOURNI ‚Üí Un mod√®le: "gpt-5.1" ou plusieurs: "gpt-5.1,sonar-pro"
      
      Mod√®les disponibles:
      ‚îú‚îÄ "GLOBAL"                    (d√©faut, score combin√©)
      ‚îú‚îÄ "gpt-5.1"                   (OpenAI GPT-5.1)
      ‚îú‚îÄ "sonar-pro"                 (Perplexity Sonar Pro)
      ‚îú‚îÄ "google-ai-overview"        (Google AI Overview)
      ‚îú‚îÄ "gpt-interface"             (GPT Interface)
      ‚îú‚îÄ "gemini-3-pro-preview"      (Google Gemini 3 Pro)
      ‚îî‚îÄ "gpt-5"                     (OpenAI GPT-5)
      
      - User demande "GPT-5.1"? ‚Üí models="gpt-5.1"
      - User demande "tous"? ‚Üí OMETS le param√®tre
      - User demande "GPT et Sonar"? ‚Üí models="gpt-5.1,sonar-pro"
      - R√®gle: SI user ne mentionne PAS de mod√®le ‚Üí OMETS ce param√®tre
    
    output_format (OPTIONNEL):
      - "tabular" (D√âFAUT): Table Markdown lisible + stats
      - "csv": CSV pur pour Excel
      - "json": JSON structur√©
      - "stats": Stats uniquement (5x rapide)
    
    EXEMPLES D'APPELS R√âELS:
    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    User: "Analyse IBIS France" (aucune date, aucun mod√®le)
    ‚Üí get_visibility_scores(domainId, topicId)
       (OMETS startDate, endDate, models)
    ‚Üí Retour: TOUTES les donn√©es, TOUS les mod√®les
    
    User: "30 derniers jours" 
    ‚Üí Calcule dates: startDate = 30j avant, endDate = aujourd'hui
    ‚Üí get_visibility_scores(domainId, topicId, startDate="...", endDate="...")
    ‚Üí Retour: Donn√©es derniers 30j, TOUS les mod√®les
    
    User: "GPT-5.1 uniquement"
    ‚Üí get_visibility_scores(domainId, topicId, models="gpt-5.1")
    ‚Üí Retour: Tous les data, FILTR√âS sur GPT-5.1
    
    User: "D√©cembre 2025, compare GPT-5.1 vs Gemini"
    ‚Üí Calcule dates: startDate="2025-12-01", endDate="2025-12-31"
    ‚Üí get_visibility_scores(
        domainId, topicId, 
        startDate="2025-12-01", 
        endDate="2025-12-31",
        models="gpt-5.1,gemini-3-pro-preview"
    )
    ‚Üí Retour: Donn√©es d√©cembre, FILTR√âES sur 2 mod√®les
    """
    
    # √âtape 1: Valider les dates
    # NOTE: Si startDate/endDate sont None, l'API retournera TOUT
    if startDate and endDate:
        # Utilise les dates fournies
        pass
    elif startDate or endDate:
        # Un seul fourni? Accept√© par l'API
        pass
    else:
        # AUCUN fourni ‚Üí API retournera TOUTES les donn√©es ‚úÖ
        pass
    
    base_params = {
        "latestOnly": "false",
        "page": "1", 
        "limit": "100"
    }
    
    # Ajouter les dates si fournies
    if startDate:
        base_params["startDate"] = startDate
    if endDate:
        base_params["endDate"] = endDate
    
    # R√©cup√©ration Global
    global_data = await fetch_api(
        f"/domains/{domainId}/topics/{topicId}/visibility/aggregated", 
        base_params
    )
    available_models = global_data.get("availableModels", [])
    
    # Filtre models si sp√©cifi√©
    models_to_fetch = []
    if models:
        # User a demand√© des mod√®les sp√©cifiques
        models_to_fetch = [m.strip() for m in models.split(",")]
    else:
        # User n'a rien demand√© ‚Üí TOUS les mod√®les ‚úÖ
        models_to_fetch = available_models
    
    # R√©cup√©ration par mod√®le
    by_model_data = {}
    for m in models_to_fetch:
        try:
            params = {**base_params, "models": m}
            by_model_data[m] = await fetch_api(
                f"/domains/{domainId}/topics/{topicId}/visibility/aggregated", 
                params
            )
        except: 
            pass

    # Construction dataset brut
    raw_dataset = []
    
    def add_rows(data, model_name):
        """Ajouter les scores au dataset brut"""
        for entry in data.get("chartData", []):
            d = entry.get("date")
            raw_dataset.append({
                "Date": d, 
                "EntityName": "Brand", 
                "EntityType": "Brand", 
                "Score": entry.get("brand"), 
                "Model": model_name
            })
            for c_name, c_score in entry.get("competitors", {}).items():
                raw_dataset.append({
                    "Date": d, 
                    "EntityName": c_name, 
                    "EntityType": "Competitor", 
                    "Score": c_score, 
                    "Model": model_name
                })

    add_rows(global_data, "GLOBAL")
    for m in models_to_fetch: 
        if m in by_model_data:
            add_rows(by_model_data[m], m)

    # Transformer en dataset tabulaire
    tabular = create_tabular_dataset(raw_dataset)
    
    # Retourner selon le format
    if output_format == "csv":
        csv_text = format_as_csv(tabular)
        return {
            "status": "success",
            "format": "csv",
            "output": csv_text,
            "metadata": {
                "total_rows": tabular.get("total_rows", 0),
                "total_entities": tabular.get("total_entities", 0),
                "models_returned": models_to_fetch if models else "ALL",
                "instruction": "Copie ce CSV dans Excel/Google Sheets"
            }
        }
    
    elif output_format == "json":
        return {
            "status": "success",
            "format": "json",
            "output": tabular,
            "metadata": {
                "all_available_models": available_models,
                "models_returned": models_to_fetch if models else "ALL",
                "date_range": f"{startDate or 'all'} to {endDate or 'all'}",
                "instruction": "Utilise ce JSON pour traitement automatis√©"
            }
        }
    
    elif output_format == "stats":
        stats_text = format_stats_summary(tabular)
        return {
            "status": "success",
            "format": "stats",
            "output": stats_text,
            "metadata": tabular.get("stats"),
            "instruction": "Ces stats permettent une analyse rapide"
        }
    
    else:  # "tabular" (d√©faut)
        markdown_text = format_as_markdown_table(tabular)
        stats_text = format_stats_summary(tabular)
        full_output = f"{stats_text}\n\n## üìã DATASET TABULAIRE\n\n{markdown_text}"
        
        return {
            "status": "success",
            "format": "tabular",
            "output": full_output,
            "metadata": {
                "total_rows": tabular.get("total_rows", 0),
                "total_entities": tabular.get("total_entities", 0),
                "entities": tabular.get("entities", []),
                "date_range": f"{startDate or 'all'} to {endDate or 'all'}",
                "all_available_models": available_models,
                "models_returned": models_to_fetch if models else "ALL",
                "instruction": "Analyse les stats + le tableau pour conclusions"
            }
        }


@server.list_tools()
async def list_tools() -> list[Tool]:
    """üìã Liste les outils disponibles"""
    return [
        Tool(
            name="get_domains_and_topics",
            description="üåç COMMENCER PAR L√Ä: Liste domaines et topics avec IDs. Utilise cet outil en premier pour trouver les domainId/topicId corrects!",
            inputSchema={"type": "object", "properties": {}}
        ),
        Tool(
            name="get_visibility_scores",
            description="üìà ANALYSE: Dataset TABULAIRE (lignes=Date+Model, colonnes=Brand+Competitors). Formats: 'tabular' (d√©faut), 'csv' (Excel), 'json', 'stats' (rapide). ‚ö†Ô∏è PARAM√àTRES OPTIONNELS: startDate/endDate (si omis ‚Üí toutes les donn√©es), models (si omis ‚Üí tous: GLOBAL, gpt-5.1, sonar-pro, google-ai-overview, gpt-interface, gemini-3-pro-preview, gpt-5)",
            inputSchema={
                "type": "object",
                "properties": {
                    "domainId": {
                        "type": "string",
                        "description": "ID du domaine (REQUIS, obtenu de get_domains_and_topics)"
                    },
                    "topicId": {
                        "type": "string",
                        "description": "ID du topic (REQUIS, obtenu de get_domains_and_topics)"
                    },
                    "startDate": {
                        "type": "string",
                        "description": "‚ö†Ô∏è OPTIONNEL: Format YYYY-MM-DD (ex: 2025-12-23). SI OMIS ‚Üí toutes les donn√©es! Ne l'utilise que si user mentionne une date de d√©but."
                    },
                    "endDate": {
                        "type": "string",
                        "description": "‚ö†Ô∏è OPTIONNEL: Format YYYY-MM-DD (ex: 2026-02-10). SI OMIS ‚Üí jusqu'√† aujourd'hui/pr√©sent! Ne l'utilise que si user mentionne une date de fin."
                    },
                    "models": {
                        "type": "string",
                        "description": "‚ö†Ô∏è OPTIONNEL: Mod√®les √† filtrer. SI OMIS ‚Üí TOUS les mod√®les! Disponibles: GLOBAL, gpt-5.1, sonar-pro, google-ai-overview, gpt-interface, gemini-3-pro-preview, gpt-5. Format: 'gpt-5.1' ou 'gpt-5.1,sonar-pro' (s√©par√©s par virgule, sans espaces). Ne l'utilise que si user demande un mod√®le sp√©cifique."
                    },
                    "output_format": {
                        "type": "string",
                        "enum": ["tabular", "csv", "json", "stats"],
                        "description": "Format sortie: 'tabular' (D√âFAUT, table+stats) | 'csv' (pour Excel) | 'json' (pour code) | 'stats' (synth√®se rapide, 5x plus rapide)"
                    }
                },
                "required": ["domainId", "topicId"]
            }
        )
    ]

@server.call_tool()
async def call_tool(name: str, arguments: Any) -> list[TextContent]:
    """üîß Ex√©cute un outil"""
    try:
        if name == "get_domains_and_topics":
            res = await get_domains_and_topics()
        elif name == "get_visibility_scores":
            res = await get_visibility_scores(**arguments)
        else:
            raise ValueError(f"Unknown tool: {name}")
        
        output = res.get("output", "")
        if isinstance(output, str):
            return [TextContent(type="text", text=output)]
        else:
            return [TextContent(type="text", text=json.dumps(res, indent=2, default=str))]
    
    except Exception as e:
        return [TextContent(type="text", text=f"‚ùå Erreur: {str(e)}")]


# ========== CONFIGURATION WEB (SSE) ==========

sse = SseServerTransport("/messages")

async def handle_sse_connect(request: Request):
    """G√®re la connexion SSE (GET)"""
    async with sse.connect_sse(request.scope, request.receive, request._send) as streams:
        await server.run(streams[0], streams[1], server.create_initialization_options())

async def handle_messages(request: Request):
    """G√®re les messages (POST)"""
    await sse.handle_post_message(request.scope, request.receive, request._send)

routes = [
    Route("/sse", endpoint=handle_sse_connect, methods=["GET"]),
    Route("/sse", endpoint=handle_messages, methods=["POST"]),
    Route("/messages", endpoint=handle_messages, methods=["POST"])
]

middleware = [
    Middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_methods=["*"],
        allow_headers=["*"],
    )
]

app = Starlette(debug=True, routes=routes, middleware=middleware)
