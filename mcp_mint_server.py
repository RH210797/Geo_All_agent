"""
Mint.ai Visibility MCP Server - Version 3.6.0 (Visibility Monthly Summary)

Serveur MCP (Model Context Protocol) permettant d'accÃ©der aux donnÃ©es de visibilitÃ©
de marques via l'API Mint.ai. Compatible avec les clients MCP standards (Claude Desktop)
et les clients Web utilisant le transport SSE (Server-Sent Events).

FonctionnalitÃ©s principales:
- RÃ©cupÃ©ration de la liste des domaines et topics disponibles
- Extraction des scores de visibilitÃ© avec historique Ã©tendu (365 jours par dÃ©faut)
- Support de multiples modÃ¨les d'IA (GPT, Gemini, Sonar, etc.)
- Format de donnÃ©es structurÃ© pour l'analyse comparative
- RÃ©cupÃ©ration des citations paginÃ©es avec agrÃ©gation par domaine source

Modifications version 3.6.0:
- Ajout du tool get_visibility_monthly_summary : agrÃ©gation multi-topics sur une pÃ©riode mensuelle
- ItÃ©ration parallÃ¨le sur tous les domaines/topics avec filtres optionnels brand/market/models
- Calcul de la moyenne de averageScore via l'endpoint /visibility (reports bruts)
- Retourne un tableau Markdown structurÃ© triÃ© par brand et score

Modifications version 3.5.0:
- Ajout du tool get_citations : rÃ©cupÃ©ration des sources citÃ©es par les LLMs dans les prompts
- AgrÃ©gation automatique : comptage du nombre de mentions par domaine source (moins de lignes)
- ParamÃ¨tres de filtrage : modÃ¨le, catÃ©gorie de prompt, pagination

Modifications version 3.4.0:
- Extension de la pÃ©riode par dÃ©faut de 30 Ã  365 jours d'historique
- Augmentation de la limite de rÃ©sultats de 100 Ã  1000 entrÃ©es
- Correction de l'erreur 405 sur l'endpoint /sse pour les clients Web

Variables d'environnement requises:
- MINT_API_KEY: ClÃ© d'authentification pour l'API Mint.ai
- MINT_BASE_URL: URL de base de l'API (dÃ©faut: https://api.getmint.ai/api)
"""

import asyncio
import json
import logging
import os
import sys
from datetime import date, timedelta
from typing import Any

import httpx
from mcp.server import Server
from mcp.types import Tool, TextContent
from mcp.server.sse import SseServerTransport

# Imports Starlette & Web
from starlette.applications import Starlette
from starlette.routing import Route
from starlette.middleware import Middleware
from starlette.middleware.cors import CORSMiddleware
from starlette.requests import Request

# ========== CONFIGURATION ==========
# Configuration de l'API Mint.ai via variables d'environnement
# Ces valeurs doivent Ãªtre dÃ©finies avant le dÃ©marrage du serveur
MINT_API_KEY = os.getenv("MINT_API_KEY", "")
MINT_BASE_URL = os.getenv("MINT_BASE_URL", "https://api.getmint.ai/api")

# Configuration du logging pour le suivi des opÃ©rations et le dÃ©bogage
# Le niveau INFO permet de suivre les principales actions du serveur
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# VÃ©rification critique: la clÃ© API est indispensable pour toutes les opÃ©rations
if not MINT_API_KEY:
    logger.warning("MINT_API_KEY environment variable is missing!")

# CrÃ©ation de l'instance du serveur MCP avec un nom identifiant unique
server = Server("mint-visibility-mcp")


# ========== LOGIQUE MÃ‰TIER (API & TOOLS) ==========

async def fetch_api(path: str, params: dict = None) -> dict:
    """
    Effectue une requÃªte GET asynchrone vers l'API Mint.ai.
    
    Cette fonction centralise tous les appels Ã  l'API externe, gÃ¨re l'authentification
    via la clÃ© API dans les headers, et propage les erreurs HTTP.
    
    Args:
        path: Chemin de l'endpoint API (ex: "/domains" ou "/domains/{id}/topics")
        params: Dictionnaire optionnel de paramÃ¨tres de requÃªte (query parameters)
    
    Returns:
        dict: RÃ©ponse JSON dÃ©sÃ©rialisÃ©e de l'API
    
    Raises:
        RuntimeError: Si MINT_API_KEY n'est pas dÃ©finie
        httpx.HTTPStatusError: Si la requÃªte Ã©choue (4xx, 5xx)
    
    Note:
        Timeout fixÃ© Ã  30 secondes pour Ã©viter les blocages prolongÃ©s
    """
    if not MINT_API_KEY:
        raise RuntimeError("MINT_API_KEY environment variable is required")
    async with httpx.AsyncClient() as client:
        response = await client.get(f"{MINT_BASE_URL}{path}", params=params or {}, headers={"X-API-Key": MINT_API_KEY}, timeout=30.0)
        response.raise_for_status()
        return response.json()

async def get_domains_and_topics() -> dict:
    """
    RÃ©cupÃ¨re la liste complÃ¨te des domaines et de leurs topics associÃ©s depuis l'API Mint.ai.
    
    Cette fonction effectue d'abord une requÃªte pour obtenir tous les domaines disponibles,
    puis pour chaque domaine, rÃ©cupÃ¨re ses topics associÃ©s. Elle construit Ã©galement un
    mapping pour faciliter la navigation entre domaines et topics.
    
    Returns:
        dict: Dictionnaire structurÃ© contenant:
            - status: "success" si l'opÃ©ration rÃ©ussit
            - data: {
                "domains": Liste complÃ¨te des domaines avec leurs mÃ©tadonnÃ©es
                "topics": Liste de tous les topics avec leur domaine parent
                "mapping": Dict {"{domain} > {topic}": {"domainId": ..., "topicId": ...}}
              }
    
    Note:
        Si la rÃ©cupÃ©ration des topics d'un domaine Ã©choue, l'erreur est ignorÃ©e
        silencieusement (ligne except: continue) pour ne pas bloquer le traitement
        des autres domaines. Cela pourrait masquer des problÃ¨mes d'accÃ¨s ou de permission.
    
    Exemple de mapping gÃ©nÃ©rÃ©:
        {"IBIS > IBIS FR": {"domainId": "694a...", "topicId": "694a..."}}
    """
    # RÃ©cupÃ©ration de la liste complÃ¨te des domaines disponibles
    domains = await fetch_api("/domains")
    all_topics = []
    mapping = {}
    
    # Pour chaque domaine, on rÃ©cupÃ¨re ses topics associÃ©s
    for domain in domains:
        d_id = domain.get("id")
        d_name = domain.get("displayName", domain.get("name", "Unknown"))
        try:
            # Appel API pour obtenir les topics du domaine courant
            topics = await fetch_api(f"/domains/{d_id}/topics")
            for topic in topics:
                t_id = topic.get("id")
                t_name = topic.get("displayName", topic.get("name", "Unknown"))
                
                # Ajout du topic Ã  la liste globale avec rÃ©fÃ©rence au domaine parent
                all_topics.append({"id": t_id, "name": t_name, "domainId": d_id, "domainName": d_name})
                
                # CrÃ©ation d'une clÃ© de mapping lisible pour faciliter la navigation
                mapping[f"{d_name} > {t_name}"] = {"domainId": d_id, "topicId": t_id}
        except Exception:
            # ATTENTION: Les erreurs sont ignorÃ©es silencieusement ici
            # Cela peut masquer des problÃ¨mes d'authentification ou de droits d'accÃ¨s
            continue
    
    return {"status": "success", "data": {"domains": domains, "topics": all_topics, "mapping": mapping}}

async def get_visibility_scores(domainId: str, topicId: str, startDate: str = None, endDate: str = None, models: str = None) -> dict:
    """
    RÃ©cupÃ¨re les scores de visibilitÃ© d'une marque et de ses concurrents sur une pÃ©riode donnÃ©e.
    
    Cette fonction constitue le cÅ“ur du serveur MCP. Elle interroge l'API Mint.ai pour obtenir
    les donnÃ©es de visibilitÃ© agrÃ©gÃ©es (score GLOBAL) ainsi que les donnÃ©es par modÃ¨le d'IA
    (GPT, Gemini, Sonar, etc.), puis construit un dataset structurÃ© pour l'analyse.
    
    Args:
        domainId: Identifiant unique du domaine (marque principale)
        topicId: Identifiant unique du topic (segment gÃ©ographique ou thÃ©matique)
        startDate: Date de dÃ©but au format YYYY-MM-DD (optionnel, dÃ©faut: aujourd'hui - 365 jours)
        endDate: Date de fin au format YYYY-MM-DD (optionnel, dÃ©faut: aujourd'hui)
        models: Liste de modÃ¨les spÃ©cifiques Ã  interroger (optionnel, sinon tous les modÃ¨les)
    
    Returns:
        dict: {
            "status": "success",
            "data": {
                "dataset": Liste de dictionnaires avec structure:
                    {
                        "Date": "YYYY-MM-DD",
                        "EntityName": "Nom de la marque ou du concurrent",
                        "EntityType": "Brand" ou "Competitor",
                        "Score": float (pourcentage de visibilitÃ©),
                        "Model": "GLOBAL" ou nom du modÃ¨le IA
                    },
                "metadata": {
                    "models": Liste des modÃ¨les inclus dans le dataset
                }
            }
        }
    
    Note sur les paramÃ¨tres par dÃ©faut:
        - PÃ©riode de 365 jours: Permet une analyse de tendances Ã  long terme
        - Limite de 1000 rÃ©sultats: Devrait couvrir l'intÃ©gralitÃ© des donnÃ©es pour une annÃ©e
        - latestOnly=false: RÃ©cupÃ¨re toutes les donnÃ©es historiques, pas seulement le dernier point
    
    Optimisation possible:
        Les appels API par modÃ¨le sont actuellement sÃ©quentiels. L'utilisation d'asyncio.gather
        permettrait de parallÃ©liser ces requÃªtes et d'amÃ©liorer significativement les performances
        lorsque de nombreux modÃ¨les sont disponibles.
    """
    # Si aucune date n'est spÃ©cifiÃ©e, on utilise les 365 derniers jours par dÃ©faut
    # Cette pÃ©riode Ã©tendue (vs 30 jours en v3.3.0) permet des analyses de tendances robustes
    if not startDate or not endDate:
        endDate = date.today().strftime("%Y-%m-%d")
        startDate = (date.today() - timedelta(days=365)).strftime("%Y-%m-%d")
    
    # ParamÃ¨tres de base pour toutes les requÃªtes API
    # - latestOnly=false: RÃ©cupÃ¨re l'historique complet, pas seulement le dernier snapshot
    # - page=1: Pagination (non utilisÃ©e actuellement, mais pourrait Ãªtre implÃ©mentÃ©e)
    # - limit=1000: Nombre maximum de points de donnÃ©es (augmentÃ© de 100 Ã  1000 en v3.4.0)
    base_params = {"startDate": startDate, "endDate": endDate, "latestOnly": "false", "page": "1", "limit": "1000"}
    
    # RÃ©cupÃ©ration des donnÃ©es agrÃ©gÃ©es GLOBAL (tous modÃ¨les confondus)
    # Cette requÃªte retourne Ã©galement la liste des modÃ¨les disponibles pour ce domaine/topic
    global_data = await fetch_api(f"/domains/{domainId}/topics/{topicId}/visibility/aggregated", base_params)
    available_models = global_data.get("availableModels", [])
    
    # RÃ©cupÃ©ration des donnÃ©es par modÃ¨le individuel (GPT-5, Gemini, Sonar, etc.)
    # ATTENTION: Cette boucle effectue des appels sÃ©quentiels qui pourraient Ãªtre parallÃ©lisÃ©s
    # avec asyncio.gather pour amÃ©liorer les performances
    by_model_data = {}
    for m in available_models:
        try:
            # Pour chaque modÃ¨le, on refait un appel avec le filtre "models" spÃ©cifique
            by_model_data[m] = await fetch_api(f"/domains/{domainId}/topics/{topicId}/visibility/aggregated", {**base_params, "models": m})
        except:
            # Les erreurs sont ignorÃ©es silencieusement pour Ã©viter qu'un modÃ¨le dÃ©faillant
            # ne bloque l'intÃ©gralitÃ© de la rÃ©cupÃ©ration. Cependant, cela masque les problÃ¨mes.
            pass

    # Construction du dataset unifiÃ© au format structurÃ©
    # Chaque ligne reprÃ©sente un score (marque ou concurrent) Ã  une date donnÃ©e pour un modÃ¨le
    dataset = []
    
    def add_rows(data, model_name):
        """
        Fonction interne pour transformer les donnÃ©es chartData de l'API en lignes de dataset.
        
        Structure de chartData de l'API:
        [
            {
                "date": "2026-01-13",
                "brand": 50.76,
                "competitors": {"Booking": 30, "B&B Hotels": 26, ...}
            },
            ...
        ]
        
        Transformation en dataset:
        - Une ligne pour la marque principale
        - Une ligne pour chaque concurrent
        - Toutes liÃ©es Ã  la mÃªme date et au mÃªme modÃ¨le
        """
        for entry in data.get("chartData", []):
            d = entry.get("date")
            # Ajout du score de la marque principale
            dataset.append({"Date": d, "EntityName": "Brand", "EntityType": "Brand", "Score": entry.get("brand"), "Model": model_name})
            # Ajout des scores de tous les concurrents pour cette date
            for c_name, c_score in entry.get("competitors", {}).items():
                dataset.append({"Date": d, "EntityName": c_name, "EntityType": "Competitor", "Score": c_score, "Model": model_name})

    # Ajout des donnÃ©es GLOBAL (agrÃ©gÃ©es tous modÃ¨les)
    add_rows(global_data, "GLOBAL")
    
    # Ajout des donnÃ©es par modÃ¨le individuel
    for m, data in by_model_data.items():
        add_rows(data, m)

    return {"status": "success", "data": {"dataset": dataset, "metadata": {"models": ["GLOBAL"] + available_models}}}


async def get_citations(
    domainId: str,
    topicId: str,
    startDate: str = None,
    endDate: str = None,
    models: str = None,
) -> dict:
    """
    RÃ©cupÃ¨re les top domaines et top URLs citÃ©s pour un topic donnÃ©,
    en bouclant sur chaque modÃ¨le disponible (mÃªme logique que get_visibility_scores).

    Utilise l'endpoint visibility/aggregated avec includeDetailedResults=true
    qui retourne directement topDomains, topCitedUrls, topDomainsOverTime, etc.
    â†’ Pas de pagination, 1 seul call par modÃ¨le.

    Args:
        domainId:   ID du domaine (REQUIS)
        topicId:    ID du topic (REQUIS)
        startDate:  Date dÃ©but YYYY-MM-DD (dÃ©faut: aujourd'hui - 90j)
        endDate:    Date fin   YYYY-MM-DD (dÃ©faut: aujourd'hui)
        models:     ModÃ¨les Ã  inclure, sÃ©parÃ©s par virgule (optionnel, dÃ©faut: tous)

    Returns:
        dict avec :
          - top_domains  : [{Model, Domain, CitationCount, Rank}, ...]
          - top_urls     : [{Model, Url, Domain, CitationCount, Rank}, ...]
          - domains_over_time : [{Model, Date, Domain, Count}, ...]
          - urls_over_time    : [{Model, Date, Url, Count}, ...]
          - global_metrics    : [{Model, TotalPrompts, TotalAnswers, TotalCitations, ReportCount}, ...]
    """
    if not startDate or not endDate:
        endDate   = date.today().strftime("%Y-%m-%d")
        startDate = (date.today() - timedelta(days=90)).strftime("%Y-%m-%d")

    base_params = {
        "startDate":              startDate,
        "endDate":                endDate,
        "includeDetailedResults": "true",
        "latestOnly":             "false",
        "page":                   "1",
        "limit":                  "1000",  # max pour rÃ©cupÃ©rer tous les top domaines/URLs sans troncature
    }

    endpoint = f"/domains/{domainId}/topics/{topicId}/visibility/aggregated"

    # â”€â”€ RÃ©cupÃ©ration GLOBAL + liste des modÃ¨les disponibles â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    global_data      = await fetch_api(endpoint, base_params)
    available_models = global_data.get("availableModels", [])

    # Filtre optionnel sur les modÃ¨les
    if models:
        requested = [m.strip() for m in models.split(",")]
        available_models = [m for m in available_models if m in requested]

    # â”€â”€ RÃ©cupÃ©ration par modÃ¨le en parallÃ¨le â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def fetch_model(m):
        try:
            return m, await fetch_api(endpoint, {**base_params, "models": m})
        except Exception:
            return m, None

    tasks = [fetch_model(m) for m in available_models]
    model_results = await asyncio.gather(*tasks)
    by_model = {m: d for m, d in model_results if d is not None}

    # â”€â”€ Extraction helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def extract(data, model_name):
        top_domains, top_urls, domains_ot, urls_ot, metrics = [], [], [], [], []

        # topDomains
        for i, item in enumerate(data.get("topDomains", []), 1):
            top_domains.append({
                "Model":         model_name,
                "Domain":        item.get("domain", item.get("linkDomain", "")),
                "CitationCount": item.get("count",  item.get("citationCount", 0)),
                "Rank":          i,
            })

        # topCitedUrls
        for i, item in enumerate(data.get("topCitedUrls", []), 1):
            top_urls.append({
                "Model":         model_name,
                "Url":           item.get("url",    item.get("link", "")),
                "Domain":        item.get("domain", item.get("linkDomain", "")),
                "CitationCount": item.get("count",  item.get("citationCount", 0)),
                "Rank":          i,
            })

        # topDomainsOverTime
        for entry in data.get("topDomainsOverTime", []):
            for domain, count in entry.get("domains", {}).items():
                domains_ot.append({
                    "Model":  model_name,
                    "Date":   entry.get("date", ""),
                    "Domain": domain,
                    "Count":  count,
                })

        # topUrlsOverTime
        for entry in data.get("topUrlsOverTime", []):
            for url, count in entry.get("urls", {}).items():
                urls_ot.append({
                    "Model": model_name,
                    "Date":  entry.get("date", ""),
                    "Url":   url,
                    "Count": count,
                })

        # global metrics
        metrics.append({
            "Model":         model_name,
            "TotalPrompts":  data.get("totalPromptsTested", 0),
            "TotalAnswers":  data.get("totalAnswers",        0),
            "TotalCitations":data.get("totalCitations",     0),
            "ReportCount":   data.get("reportCount",        0),
        })

        return top_domains, top_urls, domains_ot, urls_ot, metrics

    # â”€â”€ Assemblage du dataset final â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    all_top_domains, all_top_urls, all_domains_ot, all_urls_ot, all_metrics = [], [], [], [], []

    # GLOBAL d'abord
    td, tu, dot, uot, met = extract(global_data, "GLOBAL")
    all_top_domains  += td;  all_top_urls    += tu
    all_domains_ot   += dot; all_urls_ot     += uot
    all_metrics      += met

    # Puis chaque modÃ¨le
    for m, data in by_model.items():
        td, tu, dot, uot, met = extract(data, m)
        all_top_domains  += td;  all_top_urls    += tu
        all_domains_ot   += dot; all_urls_ot     += uot
        all_metrics      += met

    return {
        "status": "success",
        "data": {
            "top_domains":      all_top_domains,
            "top_urls":         all_top_urls,
            "domains_over_time":all_domains_ot,
            "urls_over_time":   all_urls_ot,
            "global_metrics":   all_metrics,
            "metadata": {
                "models": ["GLOBAL"] + list(by_model.keys()),
                "startDate": startDate,
                "endDate":   endDate,
            },
        },
    }

async def get_visibility_monthly_summary(
    startDate: str = None,
    endDate: str = None,
    models: str = None,
    brand_filter: str = None,
    market_filter: str = None,
) -> dict:
    """
    RÃ©cupÃ¨re et agrÃ¨ge les scores de visibilitÃ© moyens pour PLUSIEURS topics
    sur une pÃ©riode, en un seul appel. ItÃ¨re cÃ´tÃ© serveur topic par topic.

    Le tool est autonome : il rÃ©cupÃ¨re lui-mÃªme la liste des topics via
    get_domains_and_topics, applique les filtres optionnels, puis appelle
    l'endpoint /visibility pour chaque topic individuellement (1 call API
    par topic) et compile les rÃ©sultats en un tableau Markdown compact.

    Retourne uniquement le score moyen par topic â€” sans historique jour par
    jour, sans concurrents, sans dÃ©composition par modÃ¨le â€” pour minimiser
    les tokens consommÃ©s.

    Ã€ utiliser quand l'utilisateur veut une vue synthÃ©tique comparative sur
    plusieurs topics/brands/marchÃ©s sur une pÃ©riode.
    NE PAS utiliser pour zoomer sur 1 topic (Brand vs Concurrents, historique
    dÃ©taillÃ©) â†’ utiliser get_visibility_scores Ã  la place.

    Args:
        startDate:      Date dÃ©but YYYY-MM-DD (optionnel, dÃ©faut: aujourd'hui - 90j)
        endDate:        Date fin   YYYY-MM-DD (optionnel, dÃ©faut: aujourd'hui)
        models:         ModÃ¨le(s) Ã  filtrer, sÃ©parÃ©s par virgule (optionnel).
                        Ex: "gpt-5.1" ou "gpt-5.1,sonar-pro"
                        Si omis â†’ averageScore cross-modÃ¨les calculÃ© par Mint.
                        Disponibles: gpt-5.1, sonar-pro, google-ai-overview,
                                     gpt-interface, gemini-3-pro-preview
        brand_filter:   Filtrer par brand (optionnel). Ex: "IBIS", "Mercure"
        market_filter:  Filtrer par marchÃ© dans le nom du topic (optionnel).
                        Ex: "FR", "UK", "DE"

    Returns:
        dict avec:
          - markdown_table : tableau Markdown compact prÃªt Ã  afficher
          - rows           : [{brand, topic, avg_score, data_points}, ...]
          - metadata       : {startDate, endDate, models, topic_count}
    """
    if not startDate or not endDate:
        endDate   = date.today().strftime("%Y-%m-%d")
        startDate = (date.today() - timedelta(days=90)).strftime("%Y-%m-%d")

    # â”€â”€ 1. RÃ©cupÃ©rer tous les topics disponibles â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    catalog    = await get_domains_and_topics()
    all_topics = catalog.get("data", {}).get("topics", [])

    # â”€â”€ 2. Appliquer les filtres optionnels â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if brand_filter:
        all_topics = [t for t in all_topics if brand_filter.upper() in t.get("domainName", "").upper()]
    if market_filter:
        all_topics = [t for t in all_topics if market_filter.upper() in t.get("name", "").upper()]

    if not all_topics:
        return {"status": "error", "message": f"Aucun topic trouvÃ© avec brand_filter='{brand_filter}' market_filter='{market_filter}'"}

    # â”€â”€ 3. Fetch /visibility pour chaque topic â€” 1 call API par topic â”€â”€â”€â”€â”€â”€â”€â”€
    params = {"limit": 100, "startDate": startDate, "endDate": endDate}
    if models:
        params["models"] = models

    async def fetch_one(topic):
        try:
            data = await fetch_api(
                f"/domains/{topic['domainId']}/topics/{topic['id']}/visibility",
                params,
            )
            return topic, data, None
        except Exception as e:
            return topic, None, str(e)

    # Batches de 8 appels parallÃ¨les pour ne pas saturer l'API
    all_results = []
    batch_size  = 8
    for i in range(0, len(all_topics), batch_size):
        batch   = all_topics[i : i + batch_size]
        results = await asyncio.gather(*[fetch_one(t) for t in batch])
        all_results.extend(results)
        if i + batch_size < len(all_topics):
            await asyncio.sleep(0.3)

    # â”€â”€ 4. Calculer la moyenne de averageScore par topic â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def score_emoji(s):
        if s is None: return "âš ï¸"
        if s >= 60:   return "ğŸŸ¢"
        if s >= 40:   return "ğŸŸ¡"
        if s >= 20:   return "ğŸŸ "
        return "ğŸ”´"

    rows = []
    for topic, data, error in all_results:
        if error:
            rows.append({"brand": topic.get("domainName", "?"), "topic": topic.get("name", "?"),
                         "avg_score": None, "data_points": 0, "error": error})
            continue

        scores = [
            float(rep["averageScore"])
            for rep in data.get("reports", [])
            if rep.get("averageScore") is not None
        ]
        avg = round(sum(scores) / len(scores), 1) if scores else None
        rows.append({"brand": topic.get("domainName", "?"), "topic": topic.get("name", "?"),
                     "avg_score": avg, "data_points": len(scores), "error": None})

    rows.sort(key=lambda r: (r["brand"], -(r["avg_score"] or -1)))

    # â”€â”€ 5. GÃ©nÃ©rer le tableau Markdown compact â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    filter_info = ""
    if brand_filter:  filter_info += f" | brand: {brand_filter}"
    if market_filter: filter_info += f" | marchÃ©: {market_filter}"
    if models:        filter_info += f" | modÃ¨les: {models}"

    lines = [
        f"## ğŸ“Š Scores moyens â€” {startDate} â†’ {endDate}",
        f"*{len(rows)} topics{filter_info}*",
        "",
        "| Brand | Topic | Score moy. | N reports | Statut |",
        "|-------|-------|:----------:|:---------:|--------|",
    ]
    prev_brand = None
    for r in rows:
        brand_d    = r["brand"] if r["brand"] != prev_brand else ""
        prev_brand = r["brand"]
        score_str  = f"**{r['avg_score']}**" if r["avg_score"] is not None else "â€”"
        status     = score_emoji(r["avg_score"]) if not r["error"] else f"âŒ {r['error'][:30]}"
        lines.append(f"| {brand_d} | {r['topic']} | {score_str} | {r['data_points']} | {status} |")

    valid = [r["avg_score"] for r in rows if r["avg_score"] is not None]
    if valid:
        g_avg  = round(sum(valid) / len(valid), 1)
        best   = max(rows, key=lambda r: r["avg_score"] or -1)
        worst  = min(rows, key=lambda r: r["avg_score"] if r["avg_score"] is not None else 9999)
        lines += [
            "",
            "---",
            f"**Moyenne globale :** {g_avg} | **Meilleur :** {best['topic']} ({best['avg_score']}) | **Plus bas :** {worst['topic']} ({worst['avg_score']})",
            "_ğŸŸ¢ â‰¥60 | ğŸŸ¡ 40â€“59 | ğŸŸ  20â€“39 | ğŸ”´ <20 | âš ï¸ no data_",
        ]

    return {
        "status":         "success",
        "markdown_table": "\n".join(lines),
        "rows":           rows,
        "metadata":       {"startDate": startDate, "endDate": endDate,
                           "models": models or "all (cross-models)", "topic_count": len(rows)},
    }


# ========== ENREGISTREMENT DES OUTILS MCP ==========

@server.list_tools()
async def list_tools() -> list[Tool]:
    """
    DÃ©clare la liste des outils (tools) disponibles dans ce serveur MCP.
    
    Cette fonction est appelÃ©e automatiquement par le client MCP lors de la connexion
    pour dÃ©couvrir les capacitÃ©s du serveur. Chaque outil dÃ©clarÃ© ici devient accessible
    via l'interface call_tool().
    
    Returns:
        list[Tool]: Liste des outils MCP avec leurs schÃ©mas de validation
    
    Outils disponibles:
        1. get_domains_and_topics: Exploration de la hiÃ©rarchie domaines/topics
        2. get_visibility_scores: RÃ©cupÃ©ration des donnÃ©es de visibilitÃ© avec historique
    """
    return [
        Tool(
            name="get_domains_and_topics",
            description="ğŸŒ Liste tous les domaines et topics disponibles. Utilise cet outil en premier.",
            inputSchema={"type": "object", "properties": {}}
        ),
        Tool(
            name="get_visibility_scores",
            description=(
                "ğŸ“ˆ RÃ©cupÃ¨re les scores de visibilitÃ© dÃ©taillÃ©s pour UN topic spÃ©cifique : "
                "historique jour par jour, scores Brand vs Concurrents, dÃ©composition par modÃ¨le IA. "
                "Ã€ utiliser quand la question porte sur UN topic prÃ©cis (ex: 'montre-moi l'Ã©volution "
                "d'IBIS FR sur 3 mois', 'compare Brand vs concurrents sur Novotel UK'). "
                "ParamÃ¨tres optionnels: startDate/endDate (YYYY-MM-DD), "
                "models (GLOBAL,gpt-5.1,sonar-pro,google-ai-overview,gpt-interface,gemini-3-pro-preview,gpt-5). "
                "Si omis â†’ retour complet 365 jours tous modÃ¨les."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "domainId": {"type": "string", "description": "ID du domaine (REQUIS)"},
                    "topicId": {"type": "string", "description": "ID du topic (REQUIS)"},
                    "startDate": {"type": "string", "description": "Date dÃ©but YYYY-MM-DD (optionnel)"},
                    "endDate": {"type": "string", "description": "Date fin YYYY-MM-DD (optionnel)"},
                    "models": {"type": "string", "description": "ModÃ¨les Ã  filtrer (optionnel, sÃ©parÃ©s par virgule)"}
                },
                "required": ["domainId", "topicId"]
            }
        ),
        Tool(
            name="get_citations",
            description="ğŸ”— RÃ©cupÃ¨re les top domaines et top URLs citÃ©s par les LLMs, par modÃ¨le. Boucle sur tous les modÃ¨les disponibles (GLOBAL + GPT-5, Gemini, Sonar...). Retourne: top_domains, top_urls, domains_over_time, urls_over_time, global_metrics. ParamÃ¨tres optionnels: startDate/endDate (YYYY-MM-DD, dÃ©faut 90j), models (sÃ©parÃ©s par virgule).",
            inputSchema={
                "type": "object",
                "properties": {
                    "domainId":  {"type": "string", "description": "ID du domaine (REQUIS)"},
                    "topicId":   {"type": "string", "description": "ID du topic (REQUIS)"},
                    "startDate": {"type": "string", "description": "Date dÃ©but YYYY-MM-DD (optionnel, dÃ©faut: aujourd'hui - 90 jours)"},
                    "endDate":   {"type": "string", "description": "Date fin YYYY-MM-DD (optionnel, dÃ©faut: aujourd'hui)"},
                    "models":    {"type": "string", "description": "ModÃ¨les Ã  inclure, sÃ©parÃ©s par virgule (optionnel, dÃ©faut: tous)"},
                },
                "required": ["domainId", "topicId"]
            }
        ),
        Tool(
            name="get_visibility_monthly_summary",
            description=(
                "ğŸ“Š Tableau synthÃ©tique des scores moyens de visibilitÃ© pour PLUSIEURS topics. "
                "Le tool est AUTONOME : il rÃ©cupÃ¨re lui-mÃªme tous les topics disponibles, "
                "boucle dessus cÃ´tÃ© serveur (1 call API par topic), et retourne un tableau "
                "Markdown compact avec le score moyen par topic â€” sans historique, sans "
                "concurrents, sans dÃ©composition par modÃ¨le. Ã‰conomise les tokens vs appels multiples. "
                "Ã€ utiliser quand l'utilisateur veut une vue comparative sur plusieurs topics/brands "
                "(ex: 'score moyen de tous les marchÃ©s IBIS sur janvier', "
                "'compare toutes les brands sur Q1 2026', 'synthÃ¨se globale de la visibilitÃ©'). "
                "Filtres optionnels : brand_filter (ex: 'IBIS'), market_filter (ex: 'FR'). "
                "NE PAS utiliser pour zoomer sur 1 topic avec dÃ©tail Brand vs Concurrents "
                "â†’ utiliser get_visibility_scores. "
                "ModÃ¨les: gpt-5.1, sonar-pro, google-ai-overview, gpt-interface, gemini-3-pro-preview. "
                "Si models omis â†’ averageScore cross-modÃ¨les."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "startDate":     {"type": "string", "description": "Date dÃ©but YYYY-MM-DD (optionnel, dÃ©faut: aujourd'hui - 90 jours)"},
                    "endDate":       {"type": "string", "description": "Date fin YYYY-MM-DD (optionnel, dÃ©faut: aujourd'hui)"},
                    "models":        {"type": "string", "description": "ModÃ¨le(s) sÃ©parÃ©s par virgule (optionnel). Ex: 'gpt-5.1,sonar-pro'. Si omis â†’ cross-modÃ¨les."},
                    "brand_filter":  {"type": "string", "description": "Filtrer par brand (optionnel). Ex: 'IBIS', 'Mercure', 'Fairmont'"},
                    "market_filter": {"type": "string", "description": "Filtrer par marchÃ© dans le nom du topic (optionnel). Ex: 'FR', 'UK', 'DE'"},
                },
                "required": []
            }
        )
    ]

@server.call_tool()
async def call_tool(name: str, arguments: Any) -> list[TextContent]:
    """
    Point d'entrÃ©e pour l'exÃ©cution des outils MCP.
    
    Cette fonction est appelÃ©e par le client MCP lorsqu'il souhaite exÃ©cuter un outil.
    Elle route la demande vers la fonction appropriÃ©e et gÃ¨re les erreurs de maniÃ¨re centralisÃ©e.
    
    Args:
        name: Nom de l'outil Ã  exÃ©cuter (doit correspondre Ã  un outil dÃ©clarÃ© dans list_tools)
        arguments: Dictionnaire d'arguments passÃ©s Ã  l'outil (validÃ©s selon le inputSchema)
    
    Returns:
        list[TextContent]: RÃ©ponse encapsulÃ©e au format MCP (JSON sÃ©rialisÃ© en texte)
    
    Gestion des erreurs:
        Toutes les exceptions sont capturÃ©es et retournÃ©es sous forme de message d'erreur textuel.
        ATTENTION: Cette approche masque les dÃ©tails des erreurs. Une gestion plus granulaire
        permettrait de distinguer les erreurs d'authentification, de validation, de rÃ©seau, etc.
    """
    try:
        # Routage vers la fonction appropriÃ©e selon le nom de l'outil
        if name == "get_domains_and_topics":
            res = await get_domains_and_topics()
        elif name == "get_visibility_scores":
            # Expansion des arguments du dictionnaire comme paramÃ¨tres nommÃ©s
            res = await get_visibility_scores(**arguments)
        elif name == "get_citations":
            res = await get_citations(**arguments)
        elif name == "get_visibility_monthly_summary":
            res = await get_visibility_monthly_summary(**arguments)
        else:
            raise ValueError(f"Unknown tool: {name}")
        
        # SÃ©rialisation de la rÃ©ponse en JSON, avec gestion des types non-standard (dates, etc.)
        return [TextContent(type="text", text=json.dumps(res, default=str))]
    except Exception as e:
        # AMÃ‰LIORATION POSSIBLE: Distinguer les types d'erreurs pour des messages plus prÃ©cis
        # - AuthenticationError â†’ "ClÃ© API invalide ou expirÃ©e"
        # - ValidationError â†’ "ParamÃ¨tres invalides: {dÃ©tails}"
        # - NetworkError â†’ "Impossible de joindre l'API Mint.ai"
        return [TextContent(type="text", text=f"Error: {str(e)}")]


# ========== CONFIGURATION WEB (TRANSPORT SSE & ROUTING) ==========

# CrÃ©ation du transport SSE (Server-Sent Events) pour la communication MCP
# L'endpoint /messages est la route standard pour les clients MCP stricts (Claude Desktop)
sse = SseServerTransport("/messages")

async def handle_sse_connect(request: Request):
    """
    GÃ¨re la connexion initiale SSE (requÃªte GET).
    
    Cette fonction est appelÃ©e lorsqu'un client MCP Ã©tablit une connexion SSE.
    Elle crÃ©e les streams de communication bidirectionnels et lance la boucle
    principale du serveur MCP pour traiter les messages entrants.
    
    Args:
        request: RequÃªte HTTP Starlette contenant scope, receive et send
    
    Note:
        Cette fonction reste active pendant toute la durÃ©e de la session MCP.
        Elle ne se termine que lorsque le client ferme la connexion.
    """
    async with sse.connect_sse(request.scope, request.receive, request._send) as streams:
        # DÃ©marrage de la boucle principale du serveur MCP avec les streams de communication
        await server.run(streams[0], streams[1], server.create_initialization_options())

async def handle_messages(request: Request):
    """
    GÃ¨re les messages entrants (requÃªte POST).
    
    Cette fonction traite les messages JSON-RPC envoyÃ©s par le client MCP via POST.
    Elle est appelÃ©e pour chaque invocation d'outil ou requÃªte du client aprÃ¨s
    l'Ã©tablissement de la connexion SSE initiale.
    
    Args:
        request: RequÃªte HTTP POST contenant le message JSON-RPC
    """
    await sse.handle_post_message(request.scope, request.receive, request._send)

# ========== DÃ‰FINITION DES ROUTES HTTP ==========
# 
# Configuration critique pour la compatibilitÃ© multi-clients:
# - Claude Desktop et clients MCP stricts utilisent /messages (GET + POST)
# - Certains clients Web et interfaces custom utilisent /sse (GET + POST)
# 
# Le problÃ¨me rÃ©solu ici (version 3.3.0):
# Avant, seul GET Ã©tait configurÃ© sur /sse, causant des erreurs 405 (Method Not Allowed)
# lorsque des clients Web tentaient de POST des messages sur cet endpoint.
# 
# Solution: DÃ©finir explicitement GET et POST sur les deux endpoints (/sse et /messages)

routes = [
    # Endpoint /sse pour les clients Web et interfaces custom
    Route("/sse", endpoint=handle_sse_connect, methods=["GET"]),   # Connexion SSE initiale
    Route("/sse", endpoint=handle_messages, methods=["POST"]),      # Messages JSON-RPC (FIX v3.3.0)
    
    # Endpoint /messages pour les clients MCP stricts (standard du protocole)
    Route("/messages", endpoint=handle_messages, methods=["POST"])  # Messages JSON-RPC
]

# Configuration CORS (Cross-Origin Resource Sharing)
# Permet l'accÃ¨s au serveur depuis n'importe quelle origine (dÃ©veloppement/production)
# SÃ‰CURITÃ‰: En production, il serait recommandÃ© de restreindre allow_origins
# Ã  une liste explicite de domaines autorisÃ©s plutÃ´t que d'utiliser "*"
middleware = [
    Middleware(
        CORSMiddleware,
        allow_origins=["*"],        # ATTENTION: Accepte toutes les origines (permissif)
        allow_methods=["*"],        # Autorise tous les verbes HTTP
        allow_headers=["*"],        # Autorise tous les headers
    )
]

# CrÃ©ation de l'application Starlette avec la configuration complÃ¨te
# - debug=True: Active le mode dÃ©bogage (Ã  dÃ©sactiver en production)
# - routes: Configuration des endpoints HTTP
# - middleware: Stack de middlewares (CORS uniquement pour l'instant)
app = Starlette(debug=True, routes=routes, middleware=middleware)